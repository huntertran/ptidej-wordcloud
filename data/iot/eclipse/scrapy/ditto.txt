Eclipse Ditto • open source framework for digital twins in the IoT
Toggle navigation
Blog
Documentation
HTTP API
Sandbox
GitHub
GitHub examples
Links
Eclipse Ditto Project
Forum
Jenkins
Mailing list archives
Gitter.im chat
… where IoT devices and their digital twins get together
Device-as-a-Service
Provide a higher abstraction level in form of an API used to work with individual devices.
State management for digital twins
Differ between reported (last known), desired (target) and current state (live) of devices, including support for synchronization and publishing of state changes.
Organize your set of digital twins
Who's using Eclipse Ditto?
Add your logo as adopter/user of Eclipse Ditto to this list.
©2020 Eclipse Ditto.
Site last generated: Nov 17, 2020
> Privacy Policy
> Terms of Use
> Copyright Agent
> Legal
> License
> Report a Vulnerability
eclipse/ditto - Gitter
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
eclipse/ditto - Gitter
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
GitHub - eclipse/ditto-examples: Ditto Examples
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
Dashboard [Jenkins]
eclipse/ditto - Gitter
Jens Reimann
@ctron
So if I would send this via AMQP, then Ditto would accept it as is?
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
_
Sign in to start talking
Skip to contentJenkinslog inJenkinsENABLE AUTO REFRESH People Build History Project Relationship Check File FingerprintBuild QueueNo builds in the queue.Build Executor StatusAll S WNameLast SuccessLast FailureLast Duration WDescription%Test Result: 0 tests failing out of a total of 9,776 tests.100Build stability: No recent builds failed.100ditto-ci
11 hr
- #726
27 days
- #70425 min WDescription%Test Result: 0 tests failing out of a total of 1,302 tests.100Build stability: No recent builds failed.100ditto-client-java-ci
5 days 4 hr
- #106
1 mo 15 days
- #962 min 28 sec WDescription%Build stability: 4 out of the last 5 builds failed.20ditto-client-java-license-check
1 mo 1 day
- #13
1 mo 1 day
- #121 min 49 sec WDescription%Test Result: 0 tests failing out of a total of 1,296 tests.100Build stability: No recent builds failed.100ditto-client-java-release
25 days
- 1.4.0
6 mo 16 days
- #226 min 13 sec WDescription%Build stability: No recent builds failed.100ditto-client-javascript-ci
4 days 13 hr
- #921
6 mo 15 days
- #8972 min 30 sec WDescription%Build stability: 3 out of the last 5 builds failed.40ditto-client-javascript-release
6 mo 14 days
- #25
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
eclipse/ditto - Gitter
ditto/ditto-akka-config.conf at master · eclipse/ditto · GitHub
Trending
Learning Lab
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
6 mo 15 days
- #234 min 8 sec WDescription%Build stability: 4 out of the last 5 builds failed.20ditto-license-check
19 days
- #25
20 days
- #244 min 14 sec WDescription%Build stability: 1 out of the last 5 builds failed.80Test Result: 0 tests failing out of a total of 9,323 tests.100ditto-release
26 days
- 1.4.0
26 days
- #841 hr 33 min WDescription%Build stability: No recent builds failed.100ditto-website-build-and-deploy
6 days 3 hr
- #82
4 mo 18 days
- #5310 min Icon:
S M LLegend Atom feed for all Atom feed for failures Atom feed for just latest buildsPage generated: Nov 23, 2020 1:22:57 PM ESTREST APIJenkins ver. 2.222.4
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
Learning Lab
Jump to
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto-examples
Watch
16
Star
35
Fork
20
Ditto Examples
EPL-2.0 License
35
stars
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
ditto/ditto-limits.conf at master · eclipse/ditto · GitHub
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
eclipse/ditto - Gitter
Index of ditto-dev for November 2020
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
20
forks
Star
Watch
Code
Issues
2
Pull requests
5
Actions
Projects
0
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
Hi @ctronDitto cannot yet subscribe to Kafka topics, but only publish into Kafka topics .. we have an open issue for adding consumption from Kafka as wellPushing Data to Ditto using HTTP is supported via our "normal" HTTP API (HTTP noun+verb based), eg. by targeting single features to update: https://www.eclipse.org/ditto/http-api-doc.html#/FeaturesDitto however doesn't provide a "catchall POST HTTP endpoint" which would consume DittoProtocol JSON (this is what should be generated by the Vorto generator) - as we think this is more of a device facing API and is provided by Hono instead
but when you send the "Ditto Protocol JSON" via a Hono telemetry/event, this works when the Connection was setup between Ditto and Hono
Jens Reimann
@ctron
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Jens Reimann
@ctron
The result I get from Vorto looks like:{
"headers": {
"response-required": false
},
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
this is a Ditto Protocol JSON
Jens Reimann
@ctron
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Jens Reimann
@ctron
As a first step, I have pushed the data through a Vorto model conversion, having "Ditto" as the output format. However, this looks different from what I see in the Ditto HTTP API
Thomas Jaeckle
@thjaeckle
Hi @ctronDitto cannot yet subscribe to Kafka topics, but only publish into Kafka topics .. we have an open issue for adding consumption from Kafka as wellPushing Data to Ditto using HTTP is supported via our "normal" HTTP API (HTTP noun+verb based), eg. by targeting single features to update: https://www.eclipse.org/ditto/http-api-doc.html#/FeaturesDitto however doesn't provide a "catchall POST HTTP endpoint" which would consume DittoProtocol JSON (this is what should be generated by the Vorto generator) - as we think this is more of a device facing API and is provided by Hono instead
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Jens Reimann
@ctron
Hi … I got a question on getting data into Ditto. Reading in the documentation, I saw that it is possible to let ditto subscribe to Kafka, and have Ditto send HTTP requests (as output). However I would like to push new data to Ditto using HTTP, as I am using Cloud Events.
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
but when you send the "Ditto Protocol JSON" via a Hono telemetry/event, this works when the Connection was setup between Ditto and Hono
Jens Reimann
@ctron
True, that is a device facing API. However I don't have Hono in the picture. What I have is an HTTP endpoint, which gets called once a new message arrives. My goal is forward this message to Ditto in the simplest way possible. Thus HTTP came into my mind.
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
Learning Lab
Open source guides
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
eclipse/ditto - Gitter
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
when it comes to securing the HTTP and WebSocket APIs of Ditto with transport security, we recommend the SSL termination being done by a loadbalancer of the cloud Ditto is running in (sitting in front of Ditto)
Jens Reimann
Skip to main content
Edit my account
Manage Cookies
Donate
Members
Working Groups
Projects
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Eclipse Ditto | projects.eclipse.org
Jump to
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Code
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
master
5
branches
0
tags
Go to file
Code
Clone
HTTPS
GitHub CLI
Use Git or checkout with SVN using the web URL.
Work fast with our official CLI.
Learn more.
Open with GitHub Desktop
Download ZIP
Launching GitHub Desktop
True, that is a device facing API. However I don't have Hono in the picture. What I have is an HTTP endpoint, which gets called once a new message arrives. My goal is forward this message to Ditto in the simplest way possible. Thus HTTP came into my mind.
The result I get from Vorto looks like:{
"headers": {
"response-required": false
},
"path": "/features",
"topic": "foo/dev1/things/twin/commands/modify",
"value": {
"blockOne": {
"definition": [
"vorto.private.ctron:BlockOne:1.0.0"
],
"properties": {
"status": {
"temperature": "123"
}
}
}
}
}Not sure which format this is.
Thomas Jaeckle
@thjaeckle
this is a Ditto Protocol JSON
Jens Reimann
@ctron
"path": "/features",
"topic": "foo/dev1/things/twin/commands/modify",
"value": {
"blockOne": {
"definition": [
"vorto.private.ctron:BlockOne:1.0.0"
],
"properties": {
"status": {
"temperature": "123"
}
}
}
}
}Not sure which format this is.
Thomas Jaeckle
@thjaeckle
this is a Ditto Protocol JSON
Jens Reimann
@ctron
So if I would send this via AMQP, then Ditto would accept it as is?
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
So if I would send this via AMQP, then Ditto would accept it as is?
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
but when you send the "Ditto Protocol JSON" via a Hono telemetry/event, this works when the Connection was setup between Ditto and Hono
Jens Reimann
@ctron
True, that is a device facing API. However I don't have Hono in the picture. What I have is an HTTP endpoint, which gets called once a new message arrives. My goal is forward this message to Ditto in the simplest way possible. Thus HTTP came into my mind.
The result I get from Vorto looks like:{
"headers": {
"response-required": false
},
"path": "/features",
"topic": "foo/dev1/things/twin/commands/modify",
"value": {
"blockOne": {
"definition": [
"vorto.private.ctron:BlockOne:1.0.0"
],
"properties": {
"status": {
"temperature": "123"
}
}
}
}
}Not sure which format this is.
Thomas Jaeckle
As a first step, I have pushed the data through a Vorto model conversion, having "Ditto" as the output format. However, this looks different from what I see in the Ditto HTTP API
Thomas Jaeckle
@thjaeckle
Hi @ctronDitto cannot yet subscribe to Kafka topics, but only publish into Kafka topics .. we have an open issue for adding consumption from Kafka as wellPushing Data to Ditto using HTTP is supported via our "normal" HTTP API (HTTP noun+verb based), eg. by targeting single features to update: https://www.eclipse.org/ditto/http-api-doc.html#/FeaturesDitto however doesn't provide a "catchall POST HTTP endpoint" which would consume DittoProtocol JSON (this is what should be generated by the Vorto generator) - as we think this is more of a device facing API and is provided by Hono instead
but when you send the "Ditto Protocol JSON" via a Hono telemetry/event, this works when the Connection was setup between Ditto and Hono
Jens Reimann
@ctron
True, that is a device facing API. However I don't have Hono in the picture. What I have is an HTTP endpoint, which gets called once a new message arrives. My goal is forward this message to Ditto in the simplest way possible. Thus HTTP came into my mind.
The result I get from Vorto looks like:{
"headers": {
"response-required": false
},
"path": "/features",
"topic": "foo/dev1/things/twin/commands/modify",
"value": {
"blockOne": {
"definition": [
"vorto.private.ctron:BlockOne:1.0.0"
],
"properties": {
"status": {
"temperature": "123"
}
}
The result I get from Vorto looks like:{
"headers": {
"response-required": false
},
"path": "/features",
"topic": "foo/dev1/things/twin/commands/modify",
"value": {
"blockOne": {
"definition": [
"vorto.private.ctron:BlockOne:1.0.0"
],
"properties": {
"status": {
"temperature": "123"
}
}
}
}
}Not sure which format this is.
Thomas Jaeckle
@thjaeckle
this is a Ditto Protocol JSON
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
Jump to
↵
In this repository
_
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
_
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
_
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
@ctron
Hi … I got a question on getting data into Ditto. Reading in the documentation, I saw that it is possible to let ditto subscribe to Kafka, and have Ditto send HTTP requests (as output). However I would like to push new data to Ditto using HTTP, as I am using Cloud Events.
As a first step, I have pushed the data through a Vorto model conversion, having "Ditto" as the output format. However, this looks different from what I see in the Ditto HTTP API
Thomas Jaeckle
@thjaeckle
Hi @ctronDitto cannot yet subscribe to Kafka topics, but only publish into Kafka topics .. we have an open issue for adding consumption from Kafka as wellPushing Data to Ditto using HTTP is supported via our "normal" HTTP API (HTTP noun+verb based), eg. by targeting single features to update: https://www.eclipse.org/ditto/http-api-doc.html#/FeaturesDitto however doesn't provide a "catchall POST HTTP endpoint" which would consume DittoProtocol JSON (this is what should be generated by the Vorto generator) - as we think this is more of a device facing API and is provided by Hono instead
but when you send the "Ditto Protocol JSON" via a Hono telemetry/event, this works when the Connection was setup between Ditto and Hono
Jens Reimann
@ctron
True, that is a device facing API. However I don't have Hono in the picture. What I have is an HTTP endpoint, which gets called once a new message arrives. My goal is forward this message to Ditto in the simplest way possible. Thus HTTP came into my mind.
The result I get from Vorto looks like:{
"headers": {
"response-required": false
},
"path": "/features",
"topic": "foo/dev1/things/twin/commands/modify",
"value": {
"blockOne": {
"definition": [
"vorto.private.ctron:BlockOne:1.0.0"
],
"properties": {
Learn More
Documentation
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
More
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Documentation
Google Tag Manager Skip to main content
Log in
Manage Cookies
projects.eclipse.org
Download
ProjectsWorking GroupsMembersCommunity MarketplaceEventsPlanet EclipseNewsletterVideosBlogsParticipate Report a BugForumsMailing ListsWikiIRCResearchEclipse IDE DownloadLearn MoreDocumentationGetting Started / SupportHow to ContributeIDE and ToolsNewcomer Forum
More
CommunityMarketplaceEventsPlanet EclipseNewsletterVideosBlogsParticipateReport a BugForumsMailing ListsWikiIRCResearchEclipse IDEDownloadLearn MoreDocumentationGetting Started / SupportHow to ContributeIDE and ToolsNewcomer Forum
Toggle navigation
Home
Projects
Eclipse IoT
Eclipse Ditto
Eclipse Ditto
Primary tabsOverview(active tab)
Downloads
Who's Involved
Developer Resources
Governance
Contact Us
Eclipse Ditto is a framework for providing the "Digital Twin" pattern for IoT applications in order to interact with IoT devices.
That means that Ditto mirrors physical devices as digital representations in the cloud.
As a web or mobile app developer you can interact with those digital twins as if they were any other web service, that's why Ditto enables a "device as a service" paradigm.
Issues
57
Pull requests
2
Actions
Projects
1
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Permalink
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
If nothing happens, download GitHub Desktop and try again.
Go back
Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back
Launching Xcode
If nothing happens, download Xcode and try again.
Go back
Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back
Latest commit
thjaeckle
Merge pull request #39 from damian-gallo/add_influxdb_example
…
40a4a92
Aug 3, 2020
Merge pull request #39 from damian-gallo/add_influxdb_example
Add InfluxDB example
40a4a92
Git stats
116
commits
So if I would send this via AMQP, then Ditto would accept it as is?
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
@thjaeckle
this is a Ditto Protocol JSON
Jens Reimann
@ctron
So if I would send this via AMQP, then Ditto would accept it as is?
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
}
}
}Not sure which format this is.
Thomas Jaeckle
@thjaeckle
this is a Ditto Protocol JSON
Jens Reimann
@ctron
So if I would send this via AMQP, then Ditto would accept it as is?
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
Jens Reimann
@ctron
So if I would send this via AMQP, then Ditto would accept it as is?
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Code
Issues
57
Pull requests
2
Actions
Projects
1
Security
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
"status": {
"temperature": "123"
}
}
}
}
}Not sure which format this is.
Thomas Jaeckle
@thjaeckle
this is a Ditto Protocol JSON
Jens Reimann
@ctron
So if I would send this via AMQP, then Ditto would accept it as is?
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
Search
Toggle navigation
Breadcrumbs
Home
Contribute
Source code
Index of ditto-dev for November 2020
Index by Thread Index by Year [First Page] [Prev Page][Next Page] [Last Page]November 19, 2020[ditto-dev] Abgesagt: Eclipse Ditto community call Posted 06:22 by Jaeckle Thomas (IOC/PAP-TH)
Mail converted by MHonArc
Back to the top
Eclipse Foundation
About Us
Contact Us
Donate
Governance
Logo and Artwork
Board of Directors
Legal
Privacy Policy
A few of the main features are access control, a search over all twin data and push notifications.
There are various APIs in order to interact with the devices: an HTTP and WebSocket API, additionally the capability to integrate with other systems via AMQP, MQTT and Apache Kafka.
Ditto scales horizontally, so managing millions of twins is what it is designed for.
The benefit when developing IoT applications or solutions is that no own backend must be implemented, the focus can be set on the use case: for example device integration and app or web UI implementation.
Device-as-a-Service
IoT solutions have to interact with a heterogeneous set of device types, device protocols and communication patterns.
As devices are equipped with a public API (potentially public on the Internet), it is crucial to define on a device level which individuals are allowed interact with the devices. Ditto ensures that access to the device API is only granted for authorized individuals. Authentication is not scope of Ditto and delegated to existing identity providers.
With this approach your devices are turned into services with a hosted, always accessible and available API.
Devices managed by Ditto are usable as easy as any of the other services (like weather, maps, ...) within your application.
State management for Digital Twins
A digital representation of physical devices consists at its heart of the state these devices.
For IoT solutions the following information regarding state is most relevant:
Device and sensor properties like temperature, location, level, fault information, etc.
Configuration properties of sensors and actors like thresholds, intervals, ranges, toggles and limits, etc.
A good representation of this state in a Digital Twin should support different perspectives for these properties:
Reported property values based on the last transmission to the back end
Desired target property value for configuration properties
Live perspective reflecting the properties values at the current point of time
The state management provides access to all three different perspectives and helps in synchronizing between them.
Dismiss
master
ditto/services/utils/config/src/main/resources/ditto-akka-config.conf
Go to file
Go to file
T
Go to line
L
Copy path
Cannot retrieve contributors at this time
261 lines (216 sloc)
8.55 KB
Raw
Blame
akka {
loggers = ["akka.event.slf4j.Slf4jLogger"]
loglevel = "DEBUG"
logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
# for log messages during the actor system is starting up and shutting down:
stdout-loglevel = "INFO"
log-config-on-start = off
# jdk.jfr is not available in Open J9
Files
Permalink
Failed to load latest commit information.
Type
Name
Latest commit message
Commit time
azure
Wait time configurable
Jun 18, 2019
grove-ctrl
bump bootstrap to 4.3.1
Sep 27, 2019
influxdb
Add InfluxDB example
Aug 1, 2020
java-client
Changed dependencies for java-client examples
Jul 10, 2020
kata
Link to search katas in kata/README.md; adjust wording.
Apr 21, 2020
legal
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Permalink
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
master
ditto/services/utils/config/src/main/resources/ditto-limits.conf
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Terms of Use
Copyright Agent
Eclipse Public License
Legal Resources
Useful Links
Report a Bug
Documentation
How to Contribute
Mailing Lists
Forums
Marketplace
Other
IDE and Tools
Community of Projects
Working Groups
Research@Eclipse
Report a Vulnerability
Service Status
Copyright © Eclipse Foundation, Inc. All Rights Reserved.
Back to the top
Organize your set of Digital Twins
When interacting with huge amounts of devices, it can get difficult to keep track of which devices and devices types are there and how they are related (e.g. spatially).
It is wise to add meta data like e.g. manufacturer, model information, static geographic location, serial number or software version to devices in order to find them again later.
That meta data as well as the state data is automatically indexed by Ditto which leads to fast search responses provided by the search API, even when there are millions of devices to search in.
When working with sets of devices authorization information is used to determine the visibility of devices to individuals and control who can change device data.
Features at a glance
Unified resource-based HTTP JSON API representing devices
Definition of a simple "Digital Twin State Management Protocol" using JSON for command- and events-based interaction with devices
Websocket API based on this protocol in addition to the resource-based HTTP API
Establishing and maintaining connections to AMQP 0.9.1, AMQP 1.0, MQTT and Apache Kafka endpoints
Managing device meta data via APIs
Optionally configure and enforce a schema for device state (via Eclipse Vorto)
Schema evolution support for schema based device state
Accessing and setting different state perspectives
Live
Reported
Desired
Notification about changes of device resources via HTTP Server-sent events (SSE)
Authorization/Access control at device API enforcing that only allowed individuals may read/write
Search HTTP API accepting predicate-based query language
java-flight-recorder.enabled = false
io.dns {
resolver = "inet-address"
inet-address {
# To set the time to cache name resolutions
# Possible values:
# default: sun.net.InetAddressCachePolicy.get() and getNegative()
# forever: cache forever
# never: no caching
# n [time unit]: positive timeout with unit, for example "30 s"
positive-ttl = never
negative-ttl = never
}
}
discovery {
# pick the discovery method you'd like to use:
method = akka-dns
kubernetes-api {
pod-label-selector = "actorSystemName=%s"
}
# DNS based service discovery in docker swarm (without DNS ttl caching)
docker-swarm-dns {
class = org.eclipse.ditto.services.base.DockerSwarmServiceDiscovery
enhanced CONTRIBUTING.md and ajdjusted license headers in all files
Mar 28, 2019
mqtt-bidirectional
fixed example javascript template
Mar 2, 2020
octopus-via-hono
enhanced CONTRIBUTING.md and ajdjusted license headers in all files
Mar 28, 2019
payload-mapping-testing
Merge pull request #14 from bsinno/feature/payload-mapping-testrunner
Apr 30, 2019
plc4x
Added simple example for PLC4X to access a PLC.
Jan 15, 2020
rest-to-websocket
#31 Fix bug where the SmartCoffeeApp tried to deserialize a JSON mess…
Apr 2, 2020
.gitignore
Azure Event Hub example-Signed-off-by: Kai Zimmermann <kai.zimmermann…
Mar 25, 2019
CONTRIBUTING.md
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
_
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
Go to file
Go to file
T
Go to line
L
Copy path
Cannot retrieve contributors at this time
47 lines (38 sloc)
1.27 KB
Raw
Blame
ditto.limits {
headers {
# limit on the size of Ditto headers
max-size = 5k
# limits on the number of authorization subjects in Ditto headers
auth-subjects = 100
}
# limitations regarding "Thing" entity / "things" service
things {
max-size = 100k
}
GitHub - eclipse/ditto: Eclipse Ditto Project
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
Sign in to start talking
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Emit events resulting from state changes of devices which can be used
for building up a "transaction log" (e.g. using Apache Kafka)
as source for stream processing (e.g. via Apache Spark Streaming)
for building up additional persistence representations (e.g. into an InfluxDB providing optimized access to the history of a device's state properties)
for transmitting data into data analytic tools (e.g. into an Apache Hadoop HDFS)
Out-of-box integration with Eclipse Hono for communication with devices using standard or custom device protocols
Integrate Ditto in a IoT landscape
Ditto is especially useful in the context of a larger IoT landscape. In this landscape the other important aspects of a IoT solution like device communication or data analytics are covered by distinct components.
The most important integration aspect is the device communication. This is essential for the Digital Twins to really be twins of real-world physical devices.
In addition to provide a custom device communication layer Ditto will provide an out-of-the-box integration with Eclipse Hono to support device communication.
In this scenario Ditto uses Eclipse Hono in order to receive messages (e.g. state changes) from devices and to send messages (e.g. configuration changes) to devices.
Licenses: Eclipse Public License 2.0Latest Releases: From December 12th, 2019 to October 28th, 2020
NameDateReview
1.4.02020-10-28
1.3.02020-09-30
1.2.12020-09-08
1.2.02020-08-31
1.1.52020-08-25
1.1.32020-07-20
1.1.22020-07-01
1.1.12020-05-11
}
}
coordinated-shutdown.exit-jvm=on
management {
http {
bind-hostname = "0.0.0.0"
}
health-checks.readiness-checks {
# when this is empty, the cluster-membership check is disabled for readiness:
# cluster-membership = ""
}
cluster.bootstrap {
new-cluster-enabled = on
contact-point-discovery {
service-name = "ditto-cluster"
discovery-method = akka-dns
}
}
}
actor {
provider = "akka.cluster.ClusterActorRefProvider"
enable-additional-serialization-bindings = on
enhanced CONTRIBUTING.md and ajdjusted license headers in all files
Mar 28, 2019
LICENSE
initial commit
Nov 2, 2017
README.md
Add katas to ditto-examples
Apr 21, 2020
View code
README.md
Eclipse Ditto :: Examples
This repository contains examples and demonstrations of how to use Eclipse Ditto.
Projects
grove control
The grove control project shows the different communication possibilities
using Eclipse Ditto on your local machine and a Rasperry Pi with GrovePi+ board
as IoT device. This project uses Python for the Raspberry Pi code and jQuery for the Web UI.
Rest to WebSocket demo
This example shows how to combine the REST and WebSocket API of Eclipse Ditto.
This is demonstrated using a Frontend that sends REST requests and
a Thing that has a WebSocket connection to Ditto and uses it to receive
and respond to Messages. This project requires a running Eclipse Ditto
instance and a modern web browser.
Octopus via Hono to Ditto
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
# limitations regarding "Policy" entity / "policies" service
policies {
max-size = 100k
}
# limitations regarding "messages" (e.g. via WebSocket, connectivity)
messages {
max-size = 250k
headers-size = 5k
auth-subjects-count = 100
}
# limiations for the "things-search" service
things-search {
default-page-size = 25
# the allowed maximum page size limit - e.g. specified when doing a search via HTTP:
# /api/1/search/things?filter=...&option=limit(0,200)
max-page-size = 200
}
}
Copy lines
Copy permalink
View git blame
Reference in new issue
Go
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Sign in to start talking
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
_
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
1.1.02020-04-29
1.0.02019-12-12
Active Member Companies: Member companies supporting this project over the last three months.
Contribution Activity: Commits on this project (last 12 months).
Project Links
Website
Documentation
Related Projects
Related Projects:Eclipse IoTEclipse Hono
Eclipse Vorto
Eclipse TechnologyEclipse OpenJ9
Project Hierarchy:Eclipse IoT
Eclipse Ditto
Tags
Technology TypesInternet of Things
Other Tagstwin
iot
Eclipse Foundation
About UsContact UsDonateMembersGovernanceCode of ConductLogo and ArtworkBoard of Directors
Legal
Privacy PolicyTerms of UseCopyright AgentEclipse Public LicenseLegal Resources
Useful Links
Report a BugDocumentationHow to ContributeMailing ListsForumsMarketplace
# this is only intended for testing.
serialize-messages = off
serialize-creators = off
debug {
lifecycle = on
}
serializers {
json = "org.eclipse.ditto.services.utils.cluster.JsonJsonifiableSerializer"
cbor = "org.eclipse.ditto.services.utils.cluster.CborJsonifiableSerializer"
}
# Ditto custom settings:
serializers-json {
# The number of bytes per direct buffer in the pool used to read or write messages during JSON serialization
# The maximal number of direct buffers kept in the direct buffer pool for reuse
direct-buffer-pool-limit = 128
}
serialization-bindings {
#"java.io.Serializable" = none # must not be set in order to get akka.cluster.sharding.ShardRegion$GetShardRegionStats$ serialized
# Serialize Jsonifiable events with custom JSON serializer:
"org.eclipse.ditto.model.base.json.Jsonifiable" = cbor
"org.eclipse.ditto.model.base.exceptions.DittoRuntimeException" = cbor
Arduino based example on a ESP8266 board publishing read out sensor values in Ditto Protocol via
the MQTT endpoint of Eclipse Hono to a digital twin in Ditto:
BME680 sensor
temperature
humidity
barometer
BNO055 sensor
temperature
linear acceleration
angular velocity
gravity
absolute orientation
accelerometer
magnetometer
power voltage
IoT-Device connected directly to Ditto via MQTT - controlled by a custom solution
This example demonstrates how to connect an Arduino based device to Eclipse Ditto and how
payload mapping can be utilized to transform its telemetry data into a valid digital twin representation.
Furthermore a simple front-end allows manipulating the digital twin and receives twin updates
via SSE (Server Sent Events).
Parts of this example
Arduino
How to establish a network connection
How to establish a MQTT connection
How to receive and publish valid JSON data
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
_
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
_
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
_
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
_
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Trending
Learning Lab
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
_
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Other
IDE and ToolsProjectsWorking GroupsResearch@EclipseReport a VulnerabilityService Status
Copyright © Eclipse Foundation, Inc. All Rights Reserved.
Back to the top
}
default-dispatcher {
fork-join-executor {
parallelism-min = 4
parallelism-factor = 3.0
parallelism-max = 32
}
}
}
extensions = [
"akka.cluster.pubsub.DistributedPubSub"
]
remote {
log-remote-lifecycle-events = on
netty.tcp {
# InetAddress.getLocalHost.getHostAddress is used if empty
hostname = ""
port = 2551
# maximum-frame-size = 128000b # this is the default
maximum-frame-size = 256000b # 256 KiB
# send-buffer-size = 256000b # this is the default
Front-end
How to use Ditto's HTTP API for
Create policy and things
Create a connection (MQTT)
Send live messages to device
Listen to server sent events
Eclipse Ditto
How to set up Eclipse Ditto with Docker (alternatively use Ditto's Sandbox)
How to apply payload mapping on incoming messages from a connection
Samples for Microsoft Azure users
Samples to leverage Eclipse Ditto capabilities with Microsoft Azure services.
kata
A code kata is a way of learning new things and consolidating what has been learned. The presented katas serve to
understand specific features of ditto better.
About
Ditto Examples
Resources
Readme
License
EPL-2.0 License
Releases
No releases published
Packages 0
No packages published
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
_
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
_
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
Jump to
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Eclipse Ditto Project
eclipse.org/ditto/
EPL-2.0 License
216
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
send-buffer-size = 320000b # 320 KiB
# receive-buffer-size = 256000b # this is the default
receive-buffer-size = 320000b # 320 KiB
}
artery {
enabled = on
# useful default for Ditto: "tcp" - as requires less memory, CPU, etc. than "aeron-udp"
# (which is also more complicated to configure correctly):
transport = tcp
canonical {
# "<getHostAddress>" InetAddress.getLocalHost.getHostAddress
# "<getHostName>" InetAddress.getLocalHost.getHostName
hostname = "<getHostAddress>" # external (logical) hostname
port = 2551 # external (logical) port
}
bind {
hostname = "" # internal (bind) hostname -> "" means use the same as the canonical one
port = "" # internal (bind) port
}
advanced {
# Maximum serialized message size, including header data. # default: 256 KiB
maximum-frame-size = 256 KiB
Contributors 14
+ 3 contributors
Languages
Java
61.0%
JavaScript
16.3%
C++
6.9%
HTML
6.8%
Vue
4.0%
Python
3.8%
Other
1.2%
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
stars
71
forks
Star
Watch
Code
Issues
57
Pull requests
2
Actions
Projects
1
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
# Direct byte buffers are reused in a pool with this maximum size.
buffer-pool-size = 128
# Maximum serialized message size for the large messages, including header data. # default: 2 MiB
maximum-large-frame-size = 256 KiB
# Direct byte buffers for the large messages are reused in a pool with this maximum size.
large-buffer-pool-size = 32
# Size of the send queue for outgoing messages. Messages will be dropped if
# the queue becomes full.
outbound-message-queue-size = 3072
# Size of the send queue for outgoing control messages, such as system messages.
outbound-control-queue-size = 3072
# Size of the send queue for outgoing large messages. Messages will be dropped if
# the queue becomes full.
outbound-large-message-queue-size = 256
# Level of CPU time used, on a scale between 1 and 10, during backoff/idle.
# The tradeoff is that to have low latency more CPU time must be used to be
# able to react quickly on incoming messages or send as fast as possible after
# backoff backpressure.
# Level 1 strongly prefer low CPU consumption over low latency.
# Level 10 strongly prefer low latency over low CPU consumption.
idle-cpu-level = 1 # default: 5
}
}
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
master
6
branches
29
tags
Go to file
Code
Clone
HTTPS
GitHub CLI
Use Git or checkout with SVN using the web URL.
Work fast with our official CLI.
Learn more.
Open with GitHub Desktop
Download ZIP
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
watch-failure-detector.threshold = 12 # default 10
}
cluster {
# Disable legacy metrics in akka-cluster.
metrics.enabled = off
# enable weakly up feature to allow members to join even if some members are unreachable
allow-weakly-up-members = on
# required for akka-management-cluster-bootstrap (to be more robust):
shutdown-after-unsuccessful-join-seed-nodes = 60s
sharding {
state-store-mode = ddata
use-dispatcher = "sharding-dispatcher"
}
}
}
sharding-dispatcher {
# Dispatcher is the name of the event-based dispatcher
type = Dispatcher
# What kind of ExecutionService to use
executor = "fork-join-executor"
# Configuration for the fork join pool
fork-join-executor {
# Min number of threads to cap factor-based parallelism number to
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Sign in to start talking
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
Sign in to start talking
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Sign in to start talking
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Sign in to start talking
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Sign in to start talking
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
Actions · eclipse/ditto · GitHub
Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back
Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back
Launching Xcode
If nothing happens, download Xcode and try again.
Go back
Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back
Latest commit
ffendt
Merge pull request #875 from bosch-io/feature/openapi_empty_messages
…
bef90cf
Nov 23, 2020
Merge pull request #875 from bosch-io/feature/openapi_empty_messages
Allow sending empty "Messages" via the OpenAPI documentation
bef90cf
Git stats
6,299
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Sign in to start talking
parallelism-min = 4
# Parallelism (threads) ... ceil(available processors * factor)
parallelism-factor = 3.0
# Max number of threads to cap factor-based parallelism number to
parallelism-max = 32
}
# Throughput defines the maximum number of messages to be
# processed per actor before the thread jumps to the next actor.
# Set to 1 for as fair as possible.
throughput = 5 # default is 5
}
akka.contrib.persistence.mongodb.mongo {
driver = "akka.contrib.persistence.mongodb.ScalaDriverPersistenceExtension"
# Write concerns are one of: ErrorsIgnored, Unacknowledged, Acknowledged, Journaled, ReplicaAcknowledged
journal-write-concern = "Acknowledged" # By default was: "Journaled"
journal-wtimeout = 10000
journal-fsync = false
snaps-write-concern = "Acknowledged" # By default was: "Journaled"
snaps-wtimeout = 5000
snaps-fsync = false
realtime-enable-persistence = false
metrics-builder {
class = "org.eclipse.ditto.services.utils.metrics.mongo.MongoMetricsBuilder"
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Sign in to start talking
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
commits
Files
Permalink
Failed to load latest commit information.
Type
Name
Latest commit message
Commit time
.github/workflows
removed publishing test reports in GH actions
Aug 26, 2020
bom
Merge branch 'master' into feature/weak-ack
Nov 9, 2020
deployment
reconfigured nginx-cors.conf like docker-compose one: set the "origin…
Sep 29, 2020
documentation
Merge pull request #875 from bosch-io/feature/openapi_empty_messages
Nov 23, 2020
json-cbor
increased binary-compatibility-check version to released 1.3.0
Sep 30, 2020
json
}
}
Copy lines
Copy permalink
View git blame
Reference in new issue
Go
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Prevent endless redelivery for filtered out events requesting acknowledgements · Issue #852 · eclipse/ditto · GitHub
Learning Lab
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
Jump to
Issue #790 split up ditto-json and ditto-json-cbor
Sep 7, 2020
legal
updated CQs
Oct 21, 2020
model
Merge branch 'master' into feature/weak-ack
Nov 17, 2020
protocol-adapter
Review: Add desired properties in protocol-adapter
Nov 4, 2020
services
Merge pull request #875 from bosch-io/feature/openapi_empty_messages
Nov 23, 2020
signals
Issue #852: review: added missing "." at end of sentence of weak ack …
Nov 16, 2020
src
Issue #561: review: added SignalEnrichmentFacadeByRoundTripConfig and…
Jan 2, 2020
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Code
Issues
57
Pull requests
2
Actions
Projects
utils
compile ditto-utils with source- and target-level 1.8
Jan 23, 2020
.gitignore
Merged master
Apr 1, 2019
CONTRIBUTING.md
enhanced CONTRIBUTING.md with license header information
Mar 28, 2019
Jenkinsfile_multibranch_pipeline
Merge branch 'master' into feature/e2e-live
Aug 25, 2020
LICENSE
added LICENSE
Sep 26, 2018
NOTICE.md
updated legal stuff:
Mar 19, 2020
README.md
Issue #680: Fixed script for building Docker images locally.
Aug 7, 2020
pom.xml
Increment binary compatibility check version.
Trending
Learning Lab
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
1
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Workflows
All workflows
push-dockerhub
build
All workflows
push-dockerhub
build
build
Narrow your search
Oct 30, 2020
View code
README.md
Eclipse Ditto
Documentation
Find the documentation on the project site: https://eclipse.org/ditto/
Getting started
In order to start up Ditto, you'll need
a running Docker daemon (at least version 18.06 CE)
Docker Compose installed (at least version 1.22)
Start Ditto
In order to start the latest built Docker images from Docker Hub, simply execute:
cd deployment/docker/
docker-compose up -d
Check the logs after starting up:
docker-compose logs -f
Open following URL to get started: http://localhost:8080
Or have a look at the "Hello World"
Build and start Ditto locally
In order to build Ditto, you'll need
All GitHub
↵
Jump to
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Code
Issues
57
will be ignored since log searching is not yet available
Create status badge
Create status badge
802 results
802 results
Event
Filter by event
Status
Filter by status
Branch
Filter by branch
Actor
Filter by actor
increase jms client version to 0.54.0
build
#802:
Pull request #891
opened
by
Yannic92
Nov 23, 2020
23m 53s
bosch-io:feature/increase-jms-client-version
JDK 11 >= 11.0.5 and
Apache Maven 3.x installed.
In order to first build Ditto and then start the built Docker images.
1. Build Ditto with Maven
mvn clean install
2. Build local Ditto Docker snapshot images
cd services/
./build-images.sh
If your infrastructure requires a proxy, its host and port can be set using the -p option like for example:
./build-images.sh -p 172.17.0.1:3128
Please note that the given host and port automatically applies for HTTP and HTTPS.
3. Start Ditto with local snapshot images
cd ../deployment/docker/
# the "dev.env" file contains the SNAPSHOT number of Ditto, copy it to ".env" so that docker compose uses it:
cp dev.env .env
docker-compose up -d
Check the logs after starting up:
docker-compose logs -f
You have now running:
a MongoDB as backing datastore of Ditto (not part of Ditto but started via Docker)
Ditto microservices:
Policies
Things
Things-Search
Gateway
Pull requests
2
Actions
Projects
1
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
bosch-io:feature/increase-jms-client-version
Nov 23, 2020
23m 53s
View #891
View workflow file
build
build
#801:
by
ffendt
Nov 23, 2020
25m 35s
master
master
Nov 23, 2020
25m 35s
View workflow file
Feature/reduce config files
build
#800:
Pull request #888
opened
by
Connectivity
Concierge
an nginx acting as a reverse proxy performing a simple "basic authentication" listening on port 8080
including some static HTTP + API documentation on http://localhost:8080
About
Eclipse Ditto Project
eclipse.org/ditto/
Topics
eclipseiot
iot
internet-of-things
digital-twin
Resources
Readme
License
EPL-2.0 License
Releases
29
1.4.0
Latest
Oct 30, 2020
+ 28 releases
Packages 0
No packages published
New issue
Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
Pick a username
Email Address
Password
Sign up for GitHub
By clicking “Sign up for GitHub”, you agree to our terms of service and
privacy statement. We’ll occasionally send you account related emails.
Already on GitHub?
Sign in
to your account
Jump to bottom
Prevent endless redelivery for filtered out events requesting acknowledgements
Yannic92
Nov 19, 2020
25m 31s
bosch-io:feature/reduce-config-files
bosch-io:feature/reduce-config-files
Nov 19, 2020
25m 31s
View #888
View workflow file
build
build
#799:
by
thjaeckle
Nov 17, 2020
22m 32s
master
master
Nov 17, 2020
22m 32s
Contributors 28
+ 17 contributors
Languages
Java
99.4%
Scala
0.2%
CSS
0.2%
HTML
0.1%
JavaScript
0.1%
Shell
0.0%
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
#852
Closed
yufei-cai opened this issue
Oct 23, 2020
· 0 comments
Closed
Prevent endless redelivery for filtered out events requesting acknowledgements
#852
yufei-cai opened this issue
Oct 23, 2020
· 0 comments
Milestone
1.5.0
Comments
Copy link
Quote reply
Contributor
yufei-cai
commented
Oct 23, 2020
After #611, #661, #757, #792, Ditto has enough information to detect misconfigured publisher-subscriber pairs, for example:
The subscriber that declared an ack label requested by the publisher is not authorized to receive the published signal, or
The subscriber that declared an ack label requested by the publisher discards the published signal due to namespace or RQL filtering.
View workflow file
Send weak acknowledgements for dropped signals
build
#798:
Pull request #883
synchronize
by
thjaeckle
Nov 17, 2020
25m 21s
bosch-io:feature/weak-ack
bosch-io:feature/weak-ack
Nov 17, 2020
25m 21s
View #883
View workflow file
Send weak acknowledgements for dropped signals
build
#797:
Pull request #883
synchronize
by
yufei-cai
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Resending the signal will not help in these situations. Ditto should rather emit a "weak acknowledgement" that does not trigger redelivery.
thjaeckle
added
the
in progress
label
Nov 2, 2020
thjaeckle
added this to the 1.5.0 milestone
Nov 2, 2020
thjaeckle
changed the title
Prevent endless redelivery for misconfigured publisher-subscriber pairs
Prevent endless redelivery for filtered out events requesting acknowledgements
Nov 12, 2020
yufei-cai
added a commit
to bosch-io/ditto
Nov 17, 2020
8m 22s
bosch-io:feature/weak-ack
bosch-io:feature/weak-ack
Nov 17, 2020
8m 22s
View #883
View workflow file
Send weak acknowledgements for dropped signals
build
#796:
Pull request #883
opened
by
yufei-cai
Nov 17, 2020
7m 54s
bosch-io:feature/weak-ack
bosch-io:feature/weak-ack
Nov 17, 2020
7m 54s
Accept
Reject
Save preferences
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: change key type of declared ack labels DData from …
…
209fc99
…ActorRef to Address.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Fix ImmutableDittoHeadersTest.
…
143ebe8
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
View #883
View workflow file
Merge pull request #882 from bosch-io/bugfix/amqpPublisherTest
Fix nondeterministic failing of an AmqpPublisherActorTest.
build
#795:
Commit 04f7d04
pushed
by
yufei-cai
Nov 17, 2020
23m 14s
master
master
Nov 17, 2020
23m 14s
View workflow file
Fix nondeterministic failing of an AmqpPublisherActorTest.
build
#794:
Pull request #882
opened
by
yufei-cai
Nov 17, 2020
pushed a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Issue weak acknowledgements for rql filtered signa…
…
8facd90
…ls in connectivity
Signed-off-by: Yannic Klem <yannic.klem@bosch.io>
yufei-cai
pushed a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Document weak acknowledgements
…
9a156bd
Signed-off-by: Yannic Klem <yannic.klem@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
23m 42s
bosch-io:bugfix/amqpPublisherTest
bosch-io:bugfix/amqpPublisherTest
Nov 17, 2020
23m 42s
View #882
View workflow file
Merge pull request #881 from bosch-io/bugfix/desired-properties-blogpost
Minor styling/link corrections for desired properties blog post
build
#793:
Commit 8dc10bd
pushed
by
thjaeckle
Nov 13, 2020
26m 34s
master
master
Nov 13, 2020
26m 34s
View workflow file
build
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Extract acks ddata as its own extension.
…
d709494
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: add means for other actors to receive local and re…
…
a9637cc
…mote ack declarations.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Send weak acks from publishers.end weak ACK
build
#792:
by
thjaeckle
Nov 13, 2020
20m 35s
master
master
Nov 13, 2020
20m 35s
View workflow file
Minor styling/link corrections for desired properties blog post
build
#791:
Pull request #881
synchronize
by
DerSchwilk
Nov 13, 2020
22m 45s
bosch-io:bugfix/desired-properties-blogpost
bosch-io:bugfix/desired-properties-blogpost
Nov 13, 2020
…
e749a41
In addition, publishers maintains ddata snapshots instead of
requesting a snapshot from the replicator every message.
This should improve throughput at the cost of a slight delay
between ddata replication and new subscriptions becoming effective
for a publisher.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: stabilize PubSubFactoryTest.
…
c44d7bf
It is not possible to know when the publisher gets the topic
or ack declaration data replicated. Simply wait 5 heartbeats
in the test whenever replication is expected.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
22m 45s
View #881
View workflow file
Minor styling/link corrections for desired properties blog post
build
#790:
Pull request #881
synchronize
by
DerSchwilk
Nov 13, 2020
23m 24s
bosch-io:bugfix/desired-properties-blogpost
bosch-io:bugfix/desired-properties-blogpost
Nov 13, 2020
23m 24s
View #881
View workflow file
Minor styling/link corrections for desired properties blog post
build
#789:
Pull request #881
synchronize
Maven Central Repository Search
Sorry, your browser does not support JavaScript!
this issue
Nov 17, 2020
Issue eclipse#852: Send weak-acks from the subscriber side.
…
b5c9f52
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Review: rename header for weak ack; remove TODO.
…
5164604
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Update header name for documentation of WACKs. Adj…
…
469d041
by
DerSchwilk
Nov 13, 2020
25m 1s
bosch-io:bugfix/desired-properties-blogpost
bosch-io:bugfix/desired-properties-blogpost
Nov 13, 2020
25m 1s
View #881
View workflow file
Minor styling/link corrections for desired properties blog post
build
#788:
Pull request #881
synchronize
by
DerSchwilk
Nov 13, 2020
23m 52s
bosch-io:bugfix/desired-properties-blogpost
bosch-io:bugfix/desired-properties-blogpost
Nov 13, 2020
23m 52s
…ust wording.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: change how connectivity issues weak acks.
…
2aa45e6
- ConnectionPersistenceActor: issue weak acks for all requested
source-declared or target-issued custom acks if signal is dropped
due to authorization or RQL filter before enrichment.
- OutboundMappingProcessorActor: issue weak acks for all requested
source-declared or target-issued custom acks if signal is dropped
at all targets due to payload mapping or RQL filter after
enrichment.
- OutboundMappingProcessorActor: issue weak acks for requested
target-issued acknowledgements if some but not all targets
dropped the signal due to payload mapping or RQL filter after
enrichment.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
View #881
View workflow file
Minor styling/link corrections for desired properties blog post
build
#787:
Pull request #881
opened
by
DerSchwilk
Nov 13, 2020
23m 43s
bosch-io:bugfix/desired-properties-blogpost
bosch-io:bugfix/desired-properties-blogpost
Nov 13, 2020
23m 43s
View #881
View workflow file
Fixed acknowledgement filtering
build
#786:
Pull request #880
opened
by
thjaeckle
Nov 12, 2020
The Eclipse Ditto Open Source Project on Open Hub
Support for adding arbitrary _metadata for features / properties · Issue #680 · eclipse/ditto · GitHub
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Fix 2 TODOs.
…
3205bad
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Remove waiting for heartbeats after subscription i…
…
7f97897
…n PubSubFactoryTest.
The notify-subscribers-delay is now baked into subscription.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
26m 55s
bosch-io:bugfix/acks-filter
bosch-io:bugfix/acks-filter
Nov 12, 2020
26m 55s
View #880
View workflow file
Allow sending empty "Messages" via the OpenAPI documentation
build
#785:
Pull request #875
synchronize
by
ffendt
Nov 11, 2020
21m 23s
bosch-io:feature/openapi_empty_messages
bosch-io:feature/openapi_empty_messages
Nov 11, 2020
21m 23s
View #875
View workflow file
Merge pull request #879 from bosch-io/bugfix/amqp-publisher-queue-exception-handling
fix regression about (expected) exceptions thrown in AmqpPublisherActor CompletionStage
openhub.net
Black Duck Software, Inc.
Black Duck Open Hub
Follow @
OH
Sign In
Join Now
Projects
People
Organizations
Tools
Blog
Projects
People
Projects
Organizations
Forums
Eclipse Ditto
Settings
|
Report Duplicate
1
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
Learning Lab
Ditto documentation overview • Eclipse Ditto • a digital twin framework
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Remove LogUtil.
…
2bccfdb
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: Explain in WACK that it can be issued for a variet…
…
dc76ba8
…y of reasons.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
build
#784:
Commit 5fa6a82
pushed
by
stmaute
Nov 11, 2020
23m 42s
master
master
Nov 11, 2020
23m 42s
View workflow file
fix regression about (expected) exceptions thrown in AmqpPublisherActor CompletionStage
build
#783:
Pull request #879
synchronize
by
thjaeckle
Nov 11, 2020
22m 59s
I Use This!
×
Login Required
Log in to Open Hub
Remember Me
Very High Activity
Analyzed
3 days
ago.
based on code collected
3 days
ago.
Project Summary
Tags
akka cloud digitaltwin digital-twin eclipse eclipseiot iot java mongodb
In a Nutshell, Eclipse Ditto...
...
has had
6,694 commits
made by
50 contributors
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
Toggle navigation
Blog
Documentation
HTTP API
Sandbox
GitHub
GitHub examples
Links
Eclipse Ditto Project
Forum
Jenkins
Mailing list archives
Gitter.im chat
Eclipse Ditto version:
development
1.0
1.1
1.2
1.3
1.4
Important: This documentation reflects the latest 'development'. You might want to choose a released version.
Introduction
Overview
Digital twins
Hello world
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: add blog post about weak acks.
…
5f654d4
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: edit weak ack blogpost.
…
00992c4
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
pushed a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: review of blogpost:
bosch-io:bugfix/amqp-publisher-queue-exception-handling
bosch-io:bugfix/amqp-publisher-queue-exception-handling
Nov 11, 2020
22m 59s
View #879
View workflow file
fix regression about (expected) exceptions thrown in AmqpPublisherActor CompletionStage
build
#782:
Pull request #879
opened
by
thjaeckle
Nov 11, 2020
21m 56s
bosch-io:bugfix/amqp-publisher-queue-exception-handling
bosch-io:bugfix/amqp-publisher-queue-exception-handling
Nov 11, 2020
21m 56s
View #879
View workflow file
Merge pull request #877 from bosch-io/bugfix/fix-implicit-mapper-error-mapping
Fix error mapping in ImplicitThingCreationMessageMapper
representing
359,288 lines of code
...
is
mostly written in Java
with
an average number of source code comments
...
has
a codebase with a long source history
maintained by
a very large development team
with
stable Y-O-Y commits
...
took an estimated
96 years of effort
(COCOMO model)
starting with its
first commit in April, 2017
ending with its
most recent commit 5 days
ago
Quick Reference
Jump to
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Code
Issues
57
Pull requests
2
Actions
Ditto JSON is not OSGi compatible due to missing imports · Issue #790 · eclipse/ditto · GitHub
Allow sending empty "Messages" via the OpenAPI documentation by ffendt · Pull Request #875 · eclipse/ditto · GitHub
Release Notes
1.4.0
1.3.0
1.2.1
1.2.0
1.1.5
1.1.3
1.1.2
1.1.1
1.1.0
1.0.0
0.9.0
0.8.0
Milestone releases
1.0.0-M2
1.0.0-M1a
0.9.0-M2
0.9.0-M1
0.8.0-M3
0.8.0-M2
0.8.0-M1
0.3.0-M2
0.3.0-M1
0.2.0-M1
0.1.0-M3
0.1.0-M1
…
1d8b07a
* moved publish date to 16.11.2020
* fixed that ".html" was missing from links
* did some formatting (line breaks)
* fixed some findings in "desired properties" blogpost as well
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
yufei-cai
pushed a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: remove existing "requested-acks" DittoHeader when …
…
0a34f12
…creating an ImmutableAcknowledgement and an ImmutableAcknowledgements
* the header does not make sense for Acks themselves but only for the Singals which caused an Ack to be created
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
build
#781:
Commit 40398c2
pushed
by
Yannic92
Nov 9, 2020
24m 38s
master
master
Nov 9, 2020
24m 38s
View workflow file
Fix error mapping in ImplicitThingCreationMessageMapper
build
#780:
Pull request #877
synchronize
by
Yannic92
Nov 9, 2020
21m 12s
bosch-io:bugfix/fix-implicit-mapper-error-mapping
bosch-io:bugfix/fix-implicit-mapper-error-mapping
Project Links:
Homepage
Community
Documentation
Forums
Issue Trackers
Mailing Lists
Code Locations:
(2 Locations)
Similar Projects:
Managers:
Thomas Jäckle
Licenses
Eclipse Public License 2.0
Permitted
Forbidden
Required
These details are provided for information only. No information here is legal advice and should not be used as such.
All Licenses
Project Security
Vulnerabilities per Version
( last 10 releases )
There are no reported vulnerabilities
Project Vulnerability Report
Projects
1
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
New issue
Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
Pick a username
Email Address
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
Learning Lab
Open source guides
Connect with others
Installation
Building Ditto
Running Ditto
Operating Ditto
Basic concepts
Overview
Model entities
Thing
Access Control List (ACL)
Feature
Policy
Namespaces and Names
Thing Metadata
Errors
Authentication and Authorization
Messages
Signals
Signal types
Command
Command response
Error response
Event
APIs
Connections
Placeholders
Change notifications
RQL expressions
Hello world • Eclipse Ditto • a digital twin framework
Nov 17, 2020
Issue eclipse#852: fix javadoc; adjust weak ack explanations; fix fla…
…
ea5f7f2
…pping AmqpPublisherActorTest.
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
pushed a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: review: added missing "." at end of sentence of we…
…
116b2ca
…ak ack payload
* added missing "@SInCE" javadoc annotations to new public methods in Acknowledgement
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
yufei-cai
pushed a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: added to ConnectionValidator validation for that f…
Nov 9, 2020
21m 12s
View #877
View workflow file
Fix error mapping in ImplicitThingCreationMessageMapper
build
#779:
Pull request #877
opened
by
dguggemos
Nov 9, 2020
22m 35s
bosch-io:bugfix/fix-implicit-mapper-error-mapping
bosch-io:bugfix/fix-implicit-mapper-error-mapping
Nov 9, 2020
22m 35s
View #877
View workflow file
build
build
#778:
Security Confidence Index
Poor security track-record
Favorable security track-record
Vulnerability Exposure Index
Many reported vulnerabilities
Few reported vulnerabilities
About Project Vulnerability Report
Did You Know...
...
55% of companies leverage OSS for production infrastructure
...
compare projects before you chose one to use
...
there are over 3,000 projects on the Open Hub with security vulnerabilities reported against them
...
anyone with an Open Hub account can update a project's tags
About Project Security
Code
Lines of Code
Activity
Commits per Month
Community
Contributors per Month
Languages
Password
Sign up for GitHub
By clicking “Sign up for GitHub”, you agree to our terms of service and
privacy statement. We’ll occasionally send you account related emails.
Already on GitHub?
Sign in
to your account
Jump to bottom
Support for adding arbitrary _metadata for features / properties
#680
Closed
JulianFeinauer opened this issue
May 13, 2020
· 20 comments
Closed
Support for adding arbitrary _metadata for features / properties
#680
JulianFeinauer opened this issue
May 13, 2020
· 20 comments
Labels
community-interest
enhancement
Milestone
1.2.0
Learning Lab
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
Jump to
↵
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
Signal enrichment
Search
Acknowledgements / QoS
Architecture
Overview
Services
Policies
Things
Things-Search
Connectivity
Concierge
Gateway
HTTP API
Overview
Concepts
Search
Messages
WebSocket protocol binding
Server sent events
Connectivity API
Overview
Manage connections
Toggle navigation
Blog
Documentation
HTTP API
Sandbox
GitHub
GitHub examples
Links
Eclipse Ditto Project
Forum
Jenkins
Mailing list archives
Gitter.im chat
Eclipse Ditto version:
development
1.0
1.1
1.2
1.3
1.4
Important: This documentation reflects the latest 'development'. You might want to choose a released version.
Introduction
Overview
Digital twins
Hello world
…
b398dfa
…or all Connection targets the potentially declared "issuedAcknowledgementLabel" may only be issued once
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
yufei-cai
added a commit
to bosch-io/ditto
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: do not publish requests for target-issued acks.
…
612781f
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
yufei-cai
mentioned this issue
Nov 17, 2020
Send weak acknowledgements for dropped signals
#883
Merged
yufei-cai
added a commit
to bosch-io/ditto
by
yufei-cai
Nov 9, 2020
24m 28s
master
master
Nov 9, 2020
24m 28s
View workflow file
Previous Next
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Java
94%
7 Other
6%
30 Day Summary
Oct 21 2020
—
Nov 20 2020
228
Commits
13
Contributors
including
1 new contributor
12 Month Summary
Nov 20 2019
—
Nov 20 2020
2356
Commits
Up
+
371
(18%)
from previous 12 months
33
Comments
Copy link
Quote reply
Contributor
JulianFeinauer
commented
May 13, 2020
Hi all,
if considering using some kind of History API (see #545 ) it gets more and more relevant to know the timestamp of a specific value from a thing. Also in scenarios where you have no direct connection like HTTP / WS but have messaging involved like MQTT or generally Hono you can not rely that the timestamp when you receive an update message is roughly equivalent to the timestamp when it was measured.
I thus suggest to enable explicit support for "last_modified" timestamp which could be either set explicitly in the message or implicitly with the "ingestion time" and which is then available for a possible history service and for users to see how "valid" their datasets are.
👍
1
Copy link
Contributor
thjaeckle
commented
Jun 9, 2020
•
edited
Indeed that would be useful to have as metainformation for each property.
As we can't simply store the timestamp or any additional meta data it in the "target JSON" without modifying the user/device provided JSON structure, that would have to be stored besides the "target JSON" structure.
E.g. under a _metadata field:
{
"thingId": "org.eclipse.ditto:thing-1",
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Code
Issues
57
Pull requests
2
Actions
Projects
All GitHub
↵
Jump to
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Code
Issues
57
AMQP 0.9.1 protocol binding
AMQP 1.0 protocol binding
MQTT 3.1.1 protocol binding
MQTT 5 protocol binding
HTTP 1.1 protocol binding
Kafka 2.x protocol binding
Payload mapping
Header mapping
TLS certificates
Client SDK
Overview
Java
JavaScript
Ditto Protocol
Overview
Twin/live channel
Specification
Protocol topic
Things group
→ commands/events
Create/Modify
Retrieve
Delete
Acknowledgements
Errors
→ search/messages
Search
Enrich outgoing events/messages with additional fields from Thing · Issue #561 · eclipse/ditto · GitHub
Release Notes
1.4.0
1.3.0
1.2.1
1.2.0
1.1.5
1.1.3
1.1.2
1.1.1
1.1.0
1.0.0
0.9.0
0.8.0
Milestone releases
1.0.0-M2
1.0.0-M1a
0.9.0-M2
0.9.0-M1
0.8.0-M3
0.8.0-M2
0.8.0-M1
0.3.0-M2
0.3.0-M1
0.2.0-M1
0.1.0-M3
that referenced
this issue
Nov 17, 2020
Issue eclipse#852: fix javadoc links to scala classes in the same model.
…
aae72c6
Signed-off-by: Yufei Cai <yufei.cai@bosch.io>
thjaeckle
removed
the
in progress
label
Nov 17, 2020
thjaeckle
closed this
in
#883
Nov 17, 2020
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Assignees
No one assigned
Labels
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
Contributors
Up
+
12
(57%)
from previous 12 months
Most Recent Contributors
Thomas Jäckle
Dominik Guggemos
Stefan Maute
Yufei Cai
Marianne Klein
Vadim Guenther
Ratings
1 user rates this project:
5.0
5.0/5.0
Click to add your rating
Review this Project!
Project Summary
News
Settings
Sharing Widgets
"policyId": "...",
"features": {
"lamp": {
"properties": {
"on": true,
"color": {
"r": 0,
"g": 255,
"b": 255,
}
}
}
},
"_modified": "2020-06-09T14:30:00Z",
"_revision": 42,
"_metadata": {
"policyId": {
"_modified": "2020-06-09T14:00:00Z",
"_revision": 1
},
"features": {
"lamp": {
"properties": {
"on": {
"_modified": "2020-06-09T14:30:00Z",
"_revision": 42
1
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
New issue
Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
Pull requests
2
Actions
Projects
1
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
New issue
Messages
Policies group
→ commands/events
Create/Modify
Retrieve
Delete
Bindings
Examples
→ Things examples
Create a Thing
Delete a Thing
Modify a Thing
Retrieve a Thing
Retrieve multiple Things
Modify the Policy ID of a Thing
Create Attributes
Delete Attributes
Modify Attributes
Retrieve Attributes
Create a single Attribute
Delete a single Attribute
Modify a single Attribute
Retrieve a single Attribute
Create a Definition
Delete a Definition
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
Learning Lab
0.1.0-M1
Installation
Building Ditto
Running Ditto
Operating Ditto
Basic concepts
Overview
Model entities
Thing
Access Control List (ACL)
Feature
Policy
Namespaces and Names
Thing Metadata
Errors
Authentication and Authorization
Messages
Signals
Signal types
Command
Command response
Error response
Event
APIs
Connections
Placeholders
None yet
Projects
None yet
Milestone
1.5.0
Linked pull requests
Successfully merging a pull request may close this issue.
Send weak acknowledgements for dropped signals
2 participants
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
Related Projects
Code Data
Languages
Cost Estimates
Security
SCM Data
Commits
Contributors
Community Data
Users
Ratings & Reviews
User & Contributor Locations
ABOUT SYNOPSYS
Application Security Testing
Software Security Services
Program Development
Training
ABOUT OPEN HUB
Forums
Terms
Privacy
Open Hub UI Source Code
Contact Us
©
2020
},
"color": {
"r": {
"_modified": "2020-06-09T14:15:00Z",
"_revision": 23
},
"g": {
"_modified": "2020-06-09T14:15:00Z",
"_revision": 23
},
"b": {
"_modified": "2020-06-09T14:15:00Z",
"_revision": 23
}
}
}
}
}
}
}
Basically each "leaf" in the JSON gets an JsonObject containing additional meta information.
That could also be aggregated upwards, so in the provided example above you would know that the "lamp" feature is also of revision 42 last modified at the timestamp 14:30.
I would also want to see the "revision" as meta information at a property level, so that you can e.g. see (like in Subversion) which revision a part of the subtree of a Thing or even a single property has.
But that may be a topic for another issue. :)
Copy link
Contributor
Pick a username
Email Address
Password
Sign up for GitHub
By clicking “Sign up for GitHub”, you agree to our terms of service and
privacy statement. We’ll occasionally send you account related emails.
Already on GitHub?
Sign in
to your account
Jump to bottom
Ditto JSON is not OSGi compatible due to missing imports
#790
Closed
kaloyanrradev opened this issue
Sep 4, 2020
· 9 comments
Closed
Ditto JSON is not OSGi compatible due to missing imports
#790
kaloyanrradev opened this issue
Sep 4, 2020
· 9 comments
Labels
bug
Milestone
Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
Pick a username
Email Address
Password
Sign up for GitHub
By clicking “Sign up for GitHub”, you agree to our terms of service and
privacy statement. We’ll occasionally send you account related emails.
Already on GitHub?
Sign in
to your account
Jump to bottom
Allow sending empty "Messages" via the OpenAPI documentation
#875
Merged
ffendt
merged 4 commits into
eclipse:master
from
bosch-io:feature/openapi_empty_messages
Nov 23, 2020
Merged
Allow sending empty "Messages" via the OpenAPI documentation
#875
ffendt
Modify a Definition
Retrieve a Definition
Create Features
Delete Features
Modify Features
Retrieve Features
Create a single Feature
Delete a single Feature
Modify a single Feature
Retrieve a single Feature
Create Feature Definition
Delete Feature Definition
Modify Feature Definition
Retrieve Feature Definition
Create Feature Properties
Delete Feature Properties
Modify Feature Properties
Retrieve Feature Properties
Create a single Property
Delete a single Property
Modify a single Property
Retrieve a single Property
Create desired Feature Properties
Delete desired Feature Properties
Modify desired Feature Properties
Retrieve desired Feature Properties
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
Jump to
↵
In this repository
Change notifications
RQL expressions
Signal enrichment
Search
Acknowledgements / QoS
Architecture
Overview
Services
Policies
Things
Things-Search
Connectivity
Concierge
Gateway
HTTP API
Overview
Concepts
Search
Messages
WebSocket protocol binding
Server sent events
Connectivity API
Overview
Manage connections
AMQP 0.9.1 protocol binding
AMQP 1.0 protocol binding
MQTT 3.1.1 protocol binding
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
Synopsys, Inc.
All Rights Reserved.
This site uses cookies to give you the best possible experience.
By using the site, you consent to our use of cookies.
For more information, please see our
Privacy Policy
Agree
Author
JulianFeinauer
commented
Jun 9, 2020
Hey @thjaeckle welcome back : )
I would try to take care of the implementation if you generally agree. Do you have a pointer for me where to look at as start?
And I think we should also try to differentiate two things: date of last modification and timestamp of the value (which may be the same but maybe totally different also)
👍
1
Copy link
Contributor
thjaeckle
commented
Jun 9, 2020
I would try to take care of the implementation if you generally agree. Do you have a pointer for me where to look at as start?
The best way I can think of is to enhance the AbstractThingEventStrategy to - in addition to the already set "setRevision(long)" and "setModified(Instant)" also invoke something like setMetadata(JsonPointer, Metadata).
At the mentioned spot you have the ThingEvent containing which JsonPointer getResourcePath() was affected (which you need in order to set the Metadata information on the right JSON "level"), containing the Optional<JsonValue> getEntity() and also containing DittoHeaders getDittoHeaders() (which might e.g. include the "actual device modification timestamp" - propsal: "_issuedAt" - which could be a different one).
Having found that place, additional things are needed to be implemented:
the ThingBuilders (ThingBuilder.FromCopy and ThingBuilder.FromScratch) need to be enhanced by setting the new additional "meta" information
we would need a new type (Interface + immutable implementation) e.g. Metadata in package org.eclipse.ditto.model.base.entity
** the Metadata interface would define (with an inner subclass for the JsonFields) which metadata information can be expected and which Json+Java type this metadata has - for example please have a look at Thing.JsonFields
1.2.1
Comments
Copy link
Quote reply
kaloyanrradev
commented
Sep 4, 2020
Please check this line in the maven-bundle-plugin config of the Ditto JSON client bundle:
ditto/json/pom.xml
Line 176
in
1ba630b
<Import-Package>com.eclipsesource.json</Import-Package>
It needs to be cleared or extended with a star in the end, otherwise it will hide (not import) the Jackson packages used:
<Import-Package>com.eclipsesource.json,*</Import-Package>
This comment has been hidden.
Sign in to view
Copy link
Contributor
thjaeckle
merged 4 commits into
eclipse:master
from
bosch-io:feature/openapi_empty_messages
Nov 23, 2020
+116
−11
Conversation
3
Commits
4
Checks
1
Files changed
3
Conversation
Copy link
Quote reply
Contributor
ffendt
commented
Nov 6, 2020
Add a content-type none/none as a means to send empty messages with OpenAPI (as OpenAPI doesn't support requests without any content-type).
The type none/none is actually used by akka-http as a fallback if a request without any content-type information reaches an endpoint. By explicitly using the content-type none/none, we therefore forward a similar message to/from a Thing (via OpenAPI) as if it were sent without a content-type:
Create a single desired Property
Delete a single desired Property
Modify a single desired Property
Retrieve a single desired Property
Error responses
→ Policies examples
Create a Policy
Delete a Policy
Modify a Policy
Retrieve a Policy
Modify entries
Retrieve entries
Create a single entry
Delete a single entry
Modify a single entry
Retrieve a single entry
Modify subjects
Retrieve subjects
Create a single subject
Delete a single subject
Modify a single subject
Retrieve a single subject
Modify resources
Retrieve resources
Create a single resource
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto
Watch
35
Star
216
Fork
71
Code
Issues
57
Pull requests
2
Actions
Projects
1
Security
MQTT 5 protocol binding
HTTP 1.1 protocol binding
Kafka 2.x protocol binding
Payload mapping
Header mapping
TLS certificates
Client SDK
Overview
Java
JavaScript
Ditto Protocol
Overview
Twin/live channel
Specification
Protocol topic
Things group
→ commands/events
Create/Modify
Retrieve
Delete
Acknowledgements
Errors
→ search/messages
Search
ditto-dev Archive (Date View)
the org.eclipse.ditto.model.base.entity.Entity needs to be enhanced by a getter and setter for this "Metadata" instance (I would add that on Entity rather than on Thing so that the Policy also being an Entity might also benefit from that)
the Thing.JsonFields needs to be enhanced by a new constant for the "_metadata" JSON field
the ImmutableThing's JsonObject toJson(JsonSchemaVersion, Predicate<JsonField>) needs to write the new "_meta" field when serializing a Thing Java object to JSON
the ImmutableThingFromCopyBuilder of(JsonObject) needs to read the "_meta" field when deserializing to a Thing Java object again from JSON
I also think we need to enhance the DittoHeaderDefinition with a special header specifying the modification timestamp coming from a device
** then, also DittoHeaders, DittoHeadersBuilder and the implementations need to be adjusted accordingly (incl. JSON serialization)
Do you need that new meta information also in each Event emitted via Ditto (I guess so)?
Then the org.eclipse.ditto.signals.events.base.Event would need to be enhanced with that "Metadata" information as well, as well as serialization to JSON and deserialization back to Java objects in the implementations responsible for JSON serialization (e.g. in AbstractThingEvent).
Those are the first things popping into my mind.
That might seem a lot but I think this is a rather low hanging fruit - the main effort is in enhancing the Ditto "model" around Entity/Thing by adding the Metadata type and to enhance the "Event" as well.
Making the "_metadata" field in the Thing.JsonFields a FieldType.SPECIAL, FieldType.HIDDEN field (like e.g. also "_modified", the field will not by default be returned when retrieving a Thing via the HTTP API - it should work automatically then to provide a "fields" query in order to retrieve that information, e.g.:
GET /api/2/things/org.eclipse.ditto:thing-1?fields=policyId,features,_revision,_metadata
And I think we should also try to differentiate two things: date of last modification and timestamp of the value (which may be the same but maybe totally different also)
Yes, maybe we can provide a "_modified" field and in addition an optional "_issuedAt" field.
If both are the same, it is sufficient to only set the "_modified" - if they differ, both values are set in the created instance of Metadata.
The Optional<Instant> getIssuedAt() in Metadata interface would indicate that by using an Optional return type.
What do you think?
thjaeckle
added
community-interest
enhancement
labels
commented
Sep 7, 2020
Probably we did something wrong here.
ditto-json in fact has imports to com.fasterxml.jackson.core and com.fasterxml.jackson.dataformat.cbor - however catches a NoClassDefFoundError when they can't be loaded during runtime.
See https://github.com/eclipse/ditto/blob/master/json/src/main/java/org/eclipse/ditto/json/CborAvailabilityChecker.java#L38-L48
This CborAvailabilityChecker is used in both JsonObject and JsonArray implementations.
We somehow need to dynamically determine and load the CBOR classes - but in OSGi environments that could get tricky. Will have to investigate ...
thjaeckle
added
bug
in progress
labels
Sep 7, 2020
Copy link
Contributor
thjaeckle
commented
Sep 7, 2020
We're working on it.
Goal is to ship "ditto-json" with no dependency to any Jackson library, also not in scope of OSGi "imports".
thjaeckle
added this to the 1.2.1 milestone
{
"topic": "org.eclipse.ditto:thing",
"headers": {
"response-required": false,
"ditto-originator": "nginx:ditto",
"correlation-id": "009fc0ec-0282-4fc4-a3d8-84e85fef7514",
"content-type": "none/none",
"version": 2,
"timeout": "10",
"accept": "*/*",
"timestamp": "2020-11-06T13:45:01.664126345+01:00"
},
"path": "/inbox/messages/anyop",
"value": ""
}
Allow sending empty "Messages" via the OpenAPI documentation
…
Loading status checks…
f1e8bdd
Signed-off-by: Florian Fendt <Florian.Fendt@bosch.io>
Copy link
Contributor
thjaeckle
commented
Delete a single resource
Modify a single resource
Retrieve a single resource
Error responses
→ Search examples
Sandbox
Presentations
Glossary
Feedback
Collapse All | Expand All
Ditto documentation overview
What is it?
Eclipse Ditto is a technology in the IoT
implementing a software pattern called “digital twins”.
A digital twin is a virtual, cloud based, representation of his real world counterpart
(real world “Things”, e.g. devices like sensors, smart heating, connected cars, smart grids, EV charging stations, …).
The technology mirrors potentially millions and billions of digital twins residing in the digital world with physical “Things”.
This simplifies developing IoT solutions for software developers as they do not need to know how or where
exactly the physical “Things” are connected.
With Ditto a thing can just be used as any other web service via its digital twin.
What is it not?
Ditto is not another fully-fledged IoT platform. It does not provide software running on IoT gateways and it does not
define or implement an IoT protocol in order to communicate with devices.
Its focus lies on back end scenarios by providing web APIs in order to simplify working with already connected (e.g.
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
New issue
Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
Messages
Policies group
→ commands/events
Create/Modify
Retrieve
Delete
Bindings
Examples
→ Things examples
Create a Thing
Delete a Thing
Modify a Thing
Retrieve a Thing
Retrieve multiple Things
Modify the Policy ID of a Thing
Create Attributes
Delete Attributes
Modify Attributes
Retrieve Attributes
Create a single Attribute
Delete a single Attribute
Modify a single Attribute
Retrieve a single Attribute
Create a Definition
Index of ditto-dev for April 2017
Skip to main content
Edit my account
Manage Cookies
Donate
Members
Working Groups
Projects
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Index of ditto-dev for October 2020
Jun 9, 2020
This was referenced Jun 18, 2020
Distinguish between "desired" and "twin" Feature properties
#125
Closed
Provide information about desired property changes which could not be applied
#704
Open
Don't apply desired property if "applied" property was changed by device more recently
#706
Open
Copy link
Contributor
Author
JulianFeinauer
commented
Jul 6, 2020
Hi all, I had a discussion with @thjaeckle about whether we should send the information "issuedAt" in a Ditto Header or allow the user to write it through the Thing object himself. Currently there is the convention that "_xxx" fields are write protected and read only for the user. I move this discussion here that everybody can participate.
Copy link
Contributor
thjaeckle
commented
[ditto-dev] Abgesagt: Eclipse Ditto community call
Sep 7, 2020
thjaeckle
added a commit
to bosch-io/ditto
that referenced
this issue
Sep 8, 2020
Issue eclipse#790 split up ditto-json and ditto-json-cbor
…
edfdba3
* abstraction is done via a java.util.ServiceLoader
* application of the ServiceLoader in OSGi is not ensured or tested as we don't assume that someone wants to use CBOR backed serialization when e.g. using the Java Ditto-Client
* some "breaking" changes to ditto-json can be tolerated as the affected APIs can be treated as "Ditto backend internal" APIs required to apply CBOR serialization
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
thjaeckle
mentioned this issue
Sep 8, 2020
Issue #790 split up ditto-json and ditto-json-cbor
#793
Merged
thjaeckle
closed this
in
#793
Nov 7, 2020
Hm, I guess what we really wanted here is that "value" is not present at all in the Ditto Protocol message created from this call.
ffendt
added 3 commits
Nov 11, 2020
Revert "Allow sending empty "Messages" via the OpenAPI documentation"
…
5baaac4
This reverts commit f1e8bdd
Signed-off-by: Florian Fendt <Florian.Fendt@bosch.io>
Allow empty payload in the Messages route. Also fix the documentation…
…
eb391cc
… on the Ditto Protocol envelope, which had "value" as a required field. This differs from the actual implementation, as it is already possible to send protocol messages without a value.
Signed-off-by: Florian Fendt <Florian.Fendt@bosch.io>
Merge branch 'master' into feature/openapi_empty_messages
…
Loading status checks…
60a32e1
Signed-off-by: Florian Fendt <Florian.Fendt@bosch.io>
Copy link
via Eclipse Hono) devices and “Things” from customer apps or other back end software.
It also does not specify which data or which structure a “Thing” in the IoT has to provide.
When to use it?
TL;DRUse it in order to get a fully-fledged, authorization aware API
(HTTP, WebSocket and other messaging protocols) for interacting with your digital twins and all aspects around them.
Imagine you are building an IoT solution. And let’s assume that you use both hardware (e.g. sensors or actuators) and
software (e.g. a mobile or web app) in order to solve your customer’s problem.
In such a scenario you have several places where to implement software:
on or near the hardware, e.g. on an Arduino using C/C++ or on an Raspberry PI using Python,
optionally on a gateway establishing the Internet connectivity (e.g. based on Eclipse Kura),
in the mobile or web app using Java, Javascript, Swift etc.,
in the “back end” fulfilling several responsibilities like
providing an API abstracting from the hardware,
routing requests between hardware and customer apps,
ensuring only authorized access,
persisting last reported state of hardware as cache and for providing the data when hardware is currently not connected,
notifying interested parties (e.g. other back end services) about changes,
…
Ditto focuses on solving the responsibilities a typical “back end” has in such scenarios.
Its goal is to free IoT solutions from the need of implementing and operating a
custom back end. Instead by using Eclipse Ditto they can focus on business requirements, on connecting devices to
the cloud/back end and on implementing business applications.
Tags:
getting_started
ditto-dev Archive (Thread View - Most Recent First)
Pick a username
Email Address
Password
Sign up for GitHub
By clicking “Sign up for GitHub”, you agree to our terms of service and
privacy statement. We’ll occasionally send you account related emails.
Already on GitHub?
Sign in
to your account
Jump to bottom
Enrich outgoing events/messages with additional fields from Thing
#561
Closed
thjaeckle opened this issue
Dec 3, 2019
· 4 comments
Closed
Enrich outgoing events/messages with additional fields from Thing
#561
thjaeckle opened this issue
Dec 3, 2019
· 4 comments
Assignees
Labels
Delete a Definition
Modify a Definition
Retrieve a Definition
Create Features
Delete Features
Modify Features
Retrieve Features
Create a single Feature
Delete a single Feature
Modify a single Feature
Retrieve a single Feature
Create Feature Definition
Delete Feature Definition
Modify Feature Definition
Retrieve Feature Definition
Create Feature Properties
Delete Feature Properties
Modify Feature Properties
Retrieve Feature Properties
Create a single Property
Delete a single Property
Modify a single Property
Retrieve a single Property
Create desired Feature Properties
Delete desired Feature Properties
Skip to main content
Edit my account
Manage Cookies
Donate
Members
Working Groups
Projects
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Documentation
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
More
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Skip to main content
Edit my account
Manage Cookies
Donate
Members
Working Groups
Projects
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Jul 6, 2020
I would like to keep the pattern that all JSON fields starting with _ are
hidden by default (e.g. when doing a GET request)
and are read only by default (and always set by Ditto only)
Having thought about it a while I see this variant which might ease things up:
keep _metadata and as a result make everything in it read only
have specific metadata fields which Ditto automatically sets (currently: _revision and _modified)
define a prefix for header fields which should be added by Ditto into the _metadata section, e.g.: ditto-metadata:
by default, a set metadata value is applied to all JSON leaves affected by a modifying command, e.g.: ditto-metadata:issuedAt
similar to policy resources, the ditto-metadata could contain an optional JsonPointer of which property to address the metadata value to if a metadata value should not be applied to all affected JSON fields of a processed command
Example headers when modifying a complete thing (ModifyThing command - example):
{
"topic": "org.eclipse.ditto/thing-1/things/twin/commands/modify",
"headers": {
"ditto-metadata:issuedAt": "2020-06-09T14:29:00Z",
"ditto-metadata:/features/lamp/properties/color/r/issuedAt": "2020-06-09T14:14:00Z",
"ditto-metadata:/features/lamp/properties/color/g/issuedAt": "2020-06-09T14:14:00Z",
"ditto-metadata:/features/lamp/properties/color/b/issuedAt": "2020-06-09T14:14:00Z"
},
"path": "/",
Skip to main content
Edit my account
Manage Cookies
Donate
Members
Working Groups
Projects
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Documentation
Sep 8, 2020
thjaeckle
added a commit
that referenced
this issue
Sep 8, 2020
Merge pull request #793 from bosch-io/bugfix/ditto-json-cbor-dependen…
…
Verified
This commit was created on GitHub.com and signed with a verified signature using GitHub’s key.
GPG key ID: 4AEE18F83AFDEB23
Learn about signing commits
Loading status checks…
1733deb
…cies
Issue #790 split up ditto-json and ditto-json-cbor
thjaeckle
removed
the
in progress
label
Sep 8, 2020
Copy link
Contributor
Author
ffendt
commented
Nov 11, 2020
You're absolutely right. The Ditto Protocol already allows sending messages without a value.
However, the messages route didn't correctly handle HTTP requests with a content-length of 0. With the latest commits, the route correctly deserializes HTTP requests with empty body to a missing value. This way, the OpenAPI documentation will work as is.
Also, value was documented as a required field in the Ditto Protocol (which was wrong and now is fixed).
❤️
1
thjaeckle
added this to the 1.5.0 milestone
Nov 17, 2020
DerSchwilk
approved these changes
Nov 23, 2020
View changes
Copy link
Quote reply
Contributor
DerSchwilk
left a comment
LGTM 👍
©2020 Eclipse Ditto.
Site last generated: Nov 17, 2020
> Privacy Policy
> Terms of Use
> Copyright Agent
> Legal
> License
> Report a Vulnerability
Skip to main content
Edit my account
Manage Cookies
Donate
Members
Working Groups
Projects
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Documentation
enhancement
Milestone
1.1.0
Comments
Copy link
Quote reply
Contributor
thjaeckle
commented
Dec 3, 2019
•
edited
Currently, whenever a change notification / event is published (e.g. via WebSocket or the connectivity - AMQP, MQTT, Kafka, HTTP), only the actually changed values are contained in that published event.
So e.g. when only a temperature is updated (this is the Ditto Protocol message):
{
"topic": "org.eclipse.ditto/my-fancy-car/things/twin/commands/modify",
"path": "/features/temperature/properties/status/value",
"value": 23.5
}
Then a change event will only include exactly that information, as Ditto Protocol message:
{
Modify desired Feature Properties
Retrieve desired Feature Properties
Create a single desired Property
Delete a single desired Property
Modify a single desired Property
Retrieve a single desired Property
Error responses
→ Policies examples
Create a Policy
Delete a Policy
Modify a Policy
Retrieve a Policy
Modify entries
Retrieve entries
Create a single entry
Delete a single entry
Modify a single entry
Retrieve a single entry
Modify subjects
Retrieve subjects
Create a single subject
Documentation
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
More
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Documentation
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
Search
Toggle navigation
Breadcrumbs
Home
Contribute
Source code
ditto-dev Archive (Date View)
Index by Thread Index by Year [First Page] [Prev Page][Next Page] [Last Page]
2020
November
October
April
January
2019
December
November
July
Documentation
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
More
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Documentation
Getting Started / Support
"value": {
"features": {
"lamp": {
"properties": {
"on": false,
"color": {
"r": 255,
"g": 255,
"b": 0
}
}
}
}
}
}
Another example for modifying the feature properties of a thing (ModifyFeatureProperties command - example:
{
"topic": "org.eclipse.ditto/thing-1/things/twin/commands/modify",
"headers": {
"ditto-metadata:issuedAt": "2020-06-09T14:29:00Z",
"ditto-metadata:/color/r/issuedAt": "2020-06-09T14:14:00Z",
"ditto-metadata:/color/g/issuedAt": "2020-06-09T14:14:00Z",
"ditto-metadata:/color/b/issuedAt": "2020-06-09T14:14:00Z"
},
"path": "/features/lamp/properties",
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
More
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Documentation
Getting Started / Support
How to Contribute
IDE and Tools
Contributor
thjaeckle
commented
Sep 8, 2020
@kaloyanrradev how exactly did you produce this error?
We're wondering as this change is already in ditto-json since Ditto 1.1.0 which was released in April this year.
And we just tried out using the ditto-client 1.1.0 and 1.2.0 (which uses ditto-json as well) in a Felix container which worked.
thjaeckle
added a commit
that referenced
this issue
Sep 8, 2020
Issue #790 split up ditto-json and ditto-json-cbor
…
Loading status checks…
9945a56
* abstraction is done via a java.util.ServiceLoader
* application of the ServiceLoader in OSGi is not ensured or tested as we don't assume that someone wants to use CBOR backed serialization when e.g. using the Java Ditto-Client
* some "breaking" changes to ditto-json can be tolerated as the affected APIs can be treated as "Ditto backend internal" APIs required to apply CBOR serialization
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
(cherry picked from commit edfdba3)
Copy link
Hide details
View details
ffendt
merged commit bef90cf
into
eclipse:master
Nov 23, 2020
2 checks passed
2 checks passed
build
Details
eclipsefdn/eca
The author(s) of the pull request is covered by necessary legal agreements in order to proceed!
Details
ffendt
deleted the
bosch-io:feature/openapi_empty_messages
branch
Nov 23, 2020
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
eclipse/ditto - Gitter
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
More
Community
Marketplace
Events
Planet Eclipse
Newsletter
Videos
Blogs
Participate
Report a Bug
Forums
Mailing Lists
Wiki
IRC
Research
Eclipse IDE
Download
Learn More
Documentation
"topic": "org.eclipse.ditto/my-fancy-car/things/twin/events/modified",
"path": "/features/temperature/properties/status/value",
"value": 23.5
}
There are however cases when there should be more information added to that event, e.g. when some additional metadata is needed when the event is processed.
In such cases it would of course work to do a HTTP GET on the Ditto HTTP API in order to fetch that additional information, but that causes additional roundtrips and additional latency which could be avoided.
So we would like to add the possibility to specify a further field selector of additional thing data to select for all channels we send change notifications on:
WebSocket
Server Sent Events (SSEs)
all connectivity types (AMQP, MQTT, ...)
For WebSocket that could e.g. look like:
START-SEND-EVENTS?extraFields=attributes,features/location
The actual change should/could be "merged" with the additionally selected fields, so the resulting Ditto Protocol events could look like:
{
"topic": "org.eclipse.ditto/my-fancy-car/things/twin/events/modified",
"path": "/features/temperature/properties/status/value",
"value": 23.5,
"extra": {
"attributes": {
"manufacturer": "ACME corp"
},
"features": {
"location": {
"longitude": 42.123,
"latitude": 3.54
Delete a single subject
Modify a single subject
Retrieve a single subject
Modify resources
Retrieve resources
Create a single resource
Delete a single resource
Modify a single resource
Retrieve a single resource
Error responses
→ Search examples
Sandbox
Presentations
Glossary
Feedback
Collapse All | Expand All
Hello world
After starting Ditto, we have a HTTP and WebSocket API for your digital twins at our hands.
Example
Assume we want to create a digital twin for a car. The twin should hold static metadata and dynamic state data. The state data should change as often as its real world counterpart does.
Those static and dynamic types of data are mapped in the Ditto model to “attributes” (for static metadata), “features”
(for dynamic state data) and “definition” (to link a model the thing follows,
Learn More
Documentation
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
Search
Toggle navigation
Breadcrumbs
Home
Contribute
Source code
Index of ditto-dev for April 2017
Index by Thread Index by Year [First Page] [Prev Page][Next Page] [Last Page]April 08, 2017Welcome to ditto-dev Posted 00:05 by portal on behalf of emo
Mail converted by MHonArc
Back to the top
Eclipse Foundation
About Us
Contact Us
Donate
Governance
Logo and Artwork
Board of Directors
Legal
May
April
2018
November
September
July
May
2017
November
October
April
Mail converted by MHonArc
Back to the top
Eclipse Foundation
About Us
Contact Us
Donate
Governance
Logo and Artwork
Board of Directors
Legal
Privacy Policy
Terms of Use
Copyright Agent
How to Contribute
IDE and Tools
Newcomer Forum
Search
Toggle navigation
Breadcrumbs
Home
Contribute
Source code
Index of ditto-dev for October 2020
Index by Thread Index by Year [First Page] [Prev Page][Next Page] [Last Page]October 25, 2020[ditto-dev] Seeking guidance re: Ditto, Hono, and Cloud2edge package Posted 06:39 by Robinson Montalvo
Mail converted by MHonArc
Back to the top
Eclipse Foundation
About Us
Contact Us
Donate
Governance
Logo and Artwork
Board of Directors
Legal
Privacy Policy
Terms of Use
"value": {
"on": false,
"color": {
"r": 255,
"g": 255,
"b": 0
}
}
}
The resulting JSON for both of the above commands would e.g. look like:
{
"thingId": "org.eclipse.ditto:thing-1",
"policyId": "...",
"features": {
"lamp": {
"properties": {
"on": true,
"color": {
"r": 0,
"g": 255,
"b": 255,
}
}
}
},
Newcomer Forum
Search
Toggle navigation
Breadcrumbs
Home
Contribute
Source code
[Date Prev][Date Next][Thread Prev][Thread Next][Date Index][Thread Index]
[List Home]
[ditto-dev] Abgesagt: Eclipse Ditto community call
From: "Jaeckle Thomas (IOC/PAP-TH)" <Thomas.Jaeckle@xxxxxxxx>
Date: Thu, 19 Nov 2020 11:22:54 +0000
Accept-language: en-US
Arc-authentication-results: i=1; mx.microsoft.com 1; spf=pass smtp.mailfrom=bosch.io; dmarc=pass action=none header.from=bosch.io; dkim=pass header.d=bosch.io; arc=none
Arc-message-signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com; s=arcselector9901; h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck; bh=yvRJ/Aeo6QPTJgd1iYPd/v5HHAGMOWsxkALAbrJ786M=; b=eVdFPyuifsxxhCzgFvBFCmMSZc+DlE9tmzBtq0dziMSL4yYxlDoNild8BIYhVSZAilD5pT0EGs1jJVTBKho1Q3C8ysaz4kBi5OQqOHyDx81LmMRtaKeN0FlfhbrvP0aloYKmpGLW0wI+3pqeHXmdsse/GdYhW5ldJMi85gL7RAbWFfxe7gnziyQVzQvzIW/xMABovL7EGzQE28MQ5He3hW40K6qwxM/diiM1yiFNzqtqyjk9exOHpmVLDdopg/pkw5cvYIfybMofhlDkVyjxgk/4TchFiytUBKFYgrYai/9d1K6LB3d3dLgjPqCM+LL7xIJO5QukuRzpJJun8/g6Kw==
Arc-seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none; b=VcrdP3V31wZmUUYypSWDkNo8UtlMjF6C+Wvzm6yTtyhBcNH+vSNnvUpqtkLvSpO9M6Bizf+TtbxkTn3i7MTnAlv9u6Nc9bcTXl6ihrePsNOaDCKTWkBxAxILCZWRD4BBCHI9h/Ny7G2KEw6zOPGtQo/hG43Ug8xYjm2PFZ/QUVUn1IsRzDUZtg1Ab+DpKozmhIWqAPuyhwdD9CiIr8oLPL6mp7HhDqT4T/lFftklchyJ4DohNfL98FUKZTgedn9REAjh6OjfWfPtAwXuRUE8IltzLXR47O5cAcgjS/qFc03Do9ljGNhGAWLrg7BbQ4BZiLF0bMV9eaAGgvuyWPQLZw==
desislava-marinova
commented
Sep 8, 2020
@thjaeckle, as we used ditto 1.0.0 and we had no such issues, in ditto 1.1.5 the problem is also experienced.
Is the following stack trace helpful?
Caused by: java.lang.ClassNotFoundException: com.fasterxml.jackson.core.JsonFactory, from bundle org.eclipse.ditto.json at com.prosyst.mbs.impl.framework.DefaultClassProvider.loadClass_(DefaultClassProvider.java:603) ~[?:?] at com.prosyst.mbs.impl.framework.DefaultClassProvider.loadClass(DefaultClassProvider.java:453) ~[?:?] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[?:1.8.0_171] at org.eclipse.ditto.json.ImmutableJsonArray$SoftReferencedValueList.parseToList(ImmutableJsonArray.java:409) ~[?:?] at org.eclipse.ditto.json.ImmutableJsonArray$SoftReferencedValueList.recoverValues(ImmutableJsonArray.java:394) ~[?:?] at org.eclipse.ditto.json.ImmutableJsonArray$SoftReferencedValueList.values(ImmutableJsonArray.java:386) ~[?:?] at org.eclipse.ditto.json.ImmutableJsonArray$SoftReferencedValueList.getStream(ImmutableJsonArray.java:422) ~[?:?] at org.eclipse.ditto.json.ImmutableJsonArray.stream(ImmutableJsonArray.java:249) ~[?:?] at org.eclipse.ditto.model.base.headers.AbstractDittoHeaders.getAcknowledgementRequests(AbstractDittoHeaders.java:308) ~[?:?] at org.eclipse.ditto.client.internal.AbstractHandle.validateAckRequests(AbstractHandle.java:263) ~[?:?] at org.eclipse.ditto.client.internal.AbstractHandle.askThingCommand(AbstractHandle.java:167) ~[?:?] at org.eclipse.ditto.client.management.internal.FeatureHandleImpl.retrieve(FeatureHandleImpl.java:130) ~[?:?] at com.bosch.iot.dm.devices.remote.impl.DeviceInventoryRemoteImpl.lambda$null$16(DeviceInventoryRemoteImpl.java:387) ~[?:?] at com.bosch.iot.dm.async.CompletableFuture.lambda$null$24(CompletableFuture.java:973) ~[?:?] at com.bosch.iot.dm.auth.AuthCtx.callWithMDCSubscrId(AuthCtx.java:300) ~[?:?] at com.bosch.iot.dm.auth.AuthCtx.callWithMDCAuthCtx(AuthCtx.java:280) ~[?:?] at com.bosch.iot.dm.auth.AuthCtx.callAs(AuthCtx.java:239) ~[?:?] at com.bosch.iot.dm.auth.AuthCtx.callAs(AuthCtx.java:216) ~[?:?] at com.bosch.iot.dm.async.CompletableFuture.lambda$authCtxAware$25(CompletableFuture.java:973) ~[?:?] at java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:952) ~[?:1.8.0_171] at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:926) ~[?:1.8.0_171] ... 51 more
Copy link
Contributor
thjaeckle
commented
Sep 8, 2020
@desislava-marinova yes, this helps - thanks 👍
Copy link
Reviewers
DerSchwilk
Assignees
No one assigned
Labels
None yet
Projects
None yet
Milestone
1.5.0
Linked issues
Successfully merging this pull request may close these issues.
None yet
3 participants
Add this suggestion to a batch that can be applied as a single commit.
This suggestion is invalid because no changes were made to the code.
Suggestions cannot be applied while the pull request is closed.
Suggestions cannot be applied while viewing a subset of changes.
Only one suggestion per line can be applied in a batch.
Add this suggestion to a batch that can be applied as a single commit.
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
Getting Started / Support
How to Contribute
IDE and Tools
Newcomer Forum
Search
Toggle navigation
Breadcrumbs
Home
Contribute
Source code
ditto-dev Archive (Thread View - Most Recent First)
Main Index
[First Page] [Prev Page][Next Page] [Last Page]
[ditto-dev] Abgesagt: Eclipse Ditto community call,
Jaeckle Thomas (IOC/PAP-TH)
[ditto-dev] Seeking guidance re: Ditto, Hono, and Cloud2edge package,
Robinson Montalvo
[ditto-dev] Release 1.1.0 of Eclipse Ditto,
Jaeckle Thomas (IOC/PAP-TH)
[ditto-dev] [GERMAN] Webinar about Eclipse Ditto,
Julian Feinauer
[ditto-dev] Support for MQTT in ditto-client,
Julian Feinauer
}
}
}
}
Messages and live commands/events should also be able to be enriched.
👍
3
Copy link
Contributor
Author
thjaeckle
commented
Dec 5, 2019
•
edited
One additional idea in order to prevent many remoting roundtrips in the Ditto cluster:
We could cache Things at the Ditto "edges" (gateway, connectivity services).
Apply a similar approach to the policy cache in concierge:
use the Caffeine cache + cache loader in order to load non resolved Things
the Caffeine cache has to be scoped to a single connection or session
e.g. an Eclipse Vorto “information model”).
A JSON representation of some metadata and state data could for example look like this:
{
"definition": "digitaltwin:DigitaltwinExample:1.0.0",
"attributes": {
"manufacturer": "ACME",
"VIN": "0815666337"
},
"features": {
"transmission": {
"properties": {
"automatic": true,
"mode": "eco",
"cur_speed": 90,
"gear": 5
}
},
"environment-scanner": {
"properties": {
"temperature": 20.8,
"humidity": 73,
"barometricPressure": 970.7,
"location": {
"longitude": 47.682170,
"latitude": 9.386372
},
Privacy Policy
Terms of Use
Copyright Agent
Eclipse Public License
Legal Resources
Useful Links
Report a Bug
Documentation
How to Contribute
Mailing Lists
Forums
Marketplace
Other
IDE and Tools
Community of Projects
Working Groups
Research@Eclipse
Report a Vulnerability
Service Status
Copyright © Eclipse Foundation, Inc. All Rights Reserved.
Back to the top
Eclipse Public License
Legal Resources
Useful Links
Report a Bug
Documentation
How to Contribute
Mailing Lists
Forums
Marketplace
Other
IDE and Tools
Community of Projects
Working Groups
Research@Eclipse
Report a Vulnerability
Service Status
Copyright © Eclipse Foundation, Inc. All Rights Reserved.
Back to the top
Copyright Agent
Eclipse Public License
Legal Resources
Useful Links
Report a Bug
Documentation
How to Contribute
Mailing Lists
Forums
Marketplace
Other
IDE and Tools
Community of Projects
Working Groups
Research@Eclipse
Report a Vulnerability
Service Status
Copyright © Eclipse Foundation, Inc. All Rights Reserved.
Back to the top
"_modified": "2020-06-09T14:30:00Z",
"_revision": 42,
"_metadata": {
"policyId": {
"_modified": "2020-06-09T14:00:00Z",
"_revision": 1
},
"features": {
"lamp": {
"properties": {
"on": {
"_modified": "2020-06-09T14:30:00Z",
"_revision": 42,
"issuedAt": "2020-06-09T14:29:00Z"
},
"color": {
"r": {
"_modified": "2020-06-09T14:30:00Z",
"_revision": 42,
"issuedAt": "2020-06-09T14:14:00Z"
},
"g": {
"_modified": "2020-06-09T14:30:00Z",
"_revision": 42,
"issuedAt": "2020-06-09T14:14:00Z"
Delivered-to: ditto-dev@xxxxxxxxxxx
Importance: high
List-archive: <https://www.eclipse.org/mailman/private/ditto-dev>
List-help: <mailto:ditto-dev-request@eclipse.org?subject=help>
List-subscribe: <https://www.eclipse.org/mailman/listinfo/ditto-dev>, <mailto:ditto-dev-request@eclipse.org?subject=subscribe>
List-unsubscribe: <https://www.eclipse.org/mailman/options/ditto-dev>, <mailto:ditto-dev-request@eclipse.org?subject=unsubscribe>
Thread-index: AdWbkVoEG7SSfuLUTHStKA/NcfKzMEi1PYYA
Thread-topic: Eclipse Ditto community call
BEGIN:VCALENDAR
METHOD:CANCEL
PRODID:Microsoft Exchange Server 2010
VERSION:2.0
BEGIN:VTIMEZONE
TZID:W. Europe Standard Time
BEGIN:STANDARD
DTSTART:16010101T030000
TZOFFSETFROM:+0200
TZOFFSETTO:+0100
RRULE:FREQ=YEARLY;INTERVAL=1;BYDAY=-1SU;BYMONTH=10
END:STANDARD
BEGIN:DAYLIGHT
DTSTART:16010101T020000
TZOFFSETFROM:+0100
TZOFFSETTO:+0200
Contributor
thjaeckle
commented
Sep 8, 2020
Ok, our fix in PR #793 will fix that, of that I'm certain.
👍
2
thjaeckle
changed the title
Import package configuration line breaks OSGi compatibility of Ditto JSON
Ditto JSON is not OSGi compatible due to missing imports
Sep 8, 2020
Copy link
Contributor
thjaeckle
commented
Sep 8, 2020
Released as part of Ditto 1.2.1: https://www.eclipse.org/ditto/release_notes_121.html
Artifacts were published to Maven central which should have them available very soon.
Copy link
Author
kaloyanrradev
Applying suggestions on deleted lines is not supported.
You must change the existing code in this line in order to create a valid suggestion.
Outdated suggestions cannot be applied.
This suggestion has been applied or marked resolved.
Suggestions cannot be applied from pending reviews.
Suggestions cannot be applied on multi-line comments.
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
Re: [ditto-dev] Support for MQTT in ditto-client,
Jaeckle Thomas (INST/ECS1)
<Possible follow-ups>
Re: [ditto-dev] Support for MQTT in ditto-client,
Julian Feinauer
[ditto-dev] Small Example of a digital twin of a Siemens S7 using PLC4X and Ditto,
Julian Feinauer
Re: [ditto-dev] Small Example of a digital twin of a Siemens S7 using PLC4X and Ditto,
Jaeckle Thomas (INST/ECS1)
Re: [ditto-dev] Small Example of a digital twin of a Siemens S7 using PLC4X and Ditto,
Julian Feinauer
Re: [ditto-dev] Small Example of a digital twin of a Siemens S7 using PLC4X and Ditto,
Jaeckle Thomas (INST/ECS1)
Re: [ditto-dev] Small Example of a digital twin of a Siemens S7 using PLC4X and Ditto,
scoped to an "auth subject" and configured extraFields
for the first event, when the "enhanced Thing" is not yet in the cache:
load the Thing with extraFields via concierge
save the result in the cache
enhance the data from the event
the cache entry needs to be aware of the Thing revision
for all following events:
check if the revision number of the event is the expected "next one" compared to the cached Thing
if yes:
all data is available, no further "retrieve" required --> enhance the fields from the cache
do also update the cached Thing with the data from the event
increse revision number by 1
if no:
apparently the connection/session missed an event
remove the cache entry and load it again via cache loader
For the "happy path" case (which should happen >99% of the time), only very few additional roundtrips are required.
"altitude": 399
}
}
}
}
Background: Ditto only knows about “attributes”, “features” and the “definition”.
Inside “attributes” (the metadata) we can add as much JSON keys as we like with any JSON value we need.
Inside “features” (the state data) we can add as much features as we like - but each feature needs to have a “properties” JSON object.
Inside that JSON object we can add as much JSON keys as we like with any JSON value we need.
Inside “definition” we can add one JSON string value.
Creating your first Thing
We create a Thing for the example from above by using cURL. Basic authentication will use the credentials of a user “ditto”.
Those credentials have been created by default in the nginx started via “docker”.
(See ditto/deployment/docker/README.md)
curl -u ditto:ditto -X PUT -d '{
"definition": "digitaltwin:DigitaltwinExample:1.0.0",
"attributes": {
"manufacturer": "ACME",
"VIN": "0815666337"
},
"features": {
"transmission": {
"properties": {
"automatic": true,
"mode": "eco",
},
"b": {
"_modified": "2020-06-09T14:30:00Z",
"_revision": 42,
"issuedAt": "2020-06-09T14:14:00Z"
}
}
}
}
}
}
}
I think that would support the principle: "Make simple things simple, make complex things possible.
the "simple things": by adding a single header, e.g. "ditto-metadata:issuedAt": "2020-06-09T14:29:00Z" all affected JSON keys in the command will get that same metadata information
the "complex things": if that is not sufficient, a header for each differing metadata field can be added
Copy link
Contributor
Author
JulianFeinauer
commented
Jul 6, 2020
Hey @thjaeckle I really like your idea as it makes it easy to add other metadata values and is not fixed add "add timestamps". So I will try to go on like that. Thanks!
👍
RRULE:FREQ=YEARLY;INTERVAL=1;BYDAY=-1SU;BYMONTH=3
END:DAYLIGHT
END:VTIMEZONE
BEGIN:VEVENT
ORGANIZER;CN=Jaeckle Thomas (IOC/PAP-TH):mailto:Thomas.Jaeckle@xxxxxxxx
ATTENDEE;ROLE=REQ-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=ditto deve
loper discussions:mailto:ditto-dev@xxxxxxxxxxx
ATTENDEE;ROLE=REQ-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=Cai Yufei
(IOC/PAP-TH):mailto:Yufei.Cai@xxxxxxxx
ATTENDEE;ROLE=OPT-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=Klem Yanni
c (IOC/PAP-TH):mailto:Yannic.Klem@xxxxxxxx
ATTENDEE;ROLE=OPT-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=Gantert Mi
chael (IOC/PAP-TH):mailto:Michael.Gantert@xxxxxxxx
commented
Sep 9, 2020
Hi @thjaeckle, applogies for the late response - I was on a vacation last few days and many thanks for the quick reaction and fix!
DerSchwilk
pushed a commit
to bosch-io/ditto
that referenced
this issue
Sep 10, 2020
Issue eclipse#790 split up ditto-json and ditto-json-cbor
…
e4e745d
* abstraction is done via a java.util.ServiceLoader
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
Julian Feinauer
[ditto-dev] Graduation and release 1.0.0 of Eclipse Ditto,
Jaeckle Thomas (INST/ECS1)
[ditto-dev] Eclipse Ditto community call,
Jaeckle Thomas (INST/ECS1)
<Possible follow-ups>
[ditto-dev] Eclipse Ditto community call,
Jaeckle Thomas (INST/ECS1)
[ditto-dev] Eclipse Ditto community call,
Jaeckle Thomas (IOC/PAP-TH)
[ditto-dev] Eclipse Ditto community call,
Jaeckle Thomas (IOC/PAP-TH)
[ditto-dev] Release announcement of Eclipse Ditto 0.9.0,
Jaeckle Thomas (INST/ECS1)
[ditto-dev] PMC Approval required for Committer Election for Yannic Klem on Eclipse Ditto,
emo
[ditto-dev] Committer Election for Yannic Klem on Eclipse Ditto has started,
emo
[ditto-dev] PMC Approval required for Committer Election for Stefan Maute on Eclipse Ditto,
emo
[ditto-dev] Committer Election for Stefan Maute on Eclipse Ditto has started,
emo
Ditto needs some more memory consumption at the edges which should however be much better than additional cluster roundtrips.
Only problem with that approach:
Policy changes might cause that the enriched Thing is not seen the way it should be
that could be fixed by subscribing also for Policy of the Thing's Policy
additionally the cache entry could be evicted after a fix amount of time
thjaeckle
pinned this issue
Dec 9, 2019
thjaeckle
unpinned this issue
Dec 9, 2019
jufickel-b
added
the
enhancement
label
Dec 10, 2019
thjaeckle
added
the
in progress
label
Dec 11, 2019
"cur_speed": 90,
"gear": 5
}
},
"environment-scanner": {
"properties": {
"temperature": 20.8,
"humidity": 73,
"barometricPressure": 970.7,
"location": {
"longitude": 47.682170,
"latitude": 9.386372
},
"altitude": 399
}
}
}
}' 'http://localhost:8080/api/1/things/org.eclipse.ditto:fancy-car'
The result is a digital twin in Thing notation. The Thing ID is org.eclipse.ditto:fancy-car. An ID must always contain a
namespace before the :. That way Things are easier to organize.
Querying an existing Thing
By creating the digital twin as a Thing with the specified JSON format, Ditto implicitly provides an API for
our Thing.
1
JulianFeinauer
mentioned this issue
Jul 23, 2020
Time to live (TTL) for Ditto Properties with auto removal
#746
Open
thjaeckle
mentioned this issue
Jul 23, 2020
Feature/680 add metadata
#745
Merged
jufickel-b
added
the
in progress
label
Jul 28, 2020
Copy link
Contributor
jufickel-b
commented
ATTENDEE;ROLE=OPT-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=Fendt Flor
ian (IOC/PAP-TH):mailto:Florian.Fendt@xxxxxxxx
ATTENDEE;ROLE=OPT-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=INST servi
ce-things:mailto:service-things@xxxxxxxxxxxx
ATTENDEE;ROLE=OPT-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=Guenther V
adim (IOC/PAP-TH):mailto:Vadim.Guenther@xxxxxxxx
ATTENDEE;ROLE=OPT-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=Schwilk Da
vid (IOC/PAP-TH):mailto:David.Schwilk@xxxxxxxx
ATTENDEE;ROLE=OPT-PARTICIPANT;PARTSTAT=NEEDS-ACTION;RSVP=TRUE;CN=Fickel Jue
rgen (IOC/PAP-TH):mailto:Juergen.Fickel@xxxxxxxx
DESCRIPTION;LANGUAGE=de-DE:Hello Ditto community.\n\nOne of our adopters an
d contributors\, Bob from Aloxy\, reached out to the Ditto team asking whe
ther we could do regular community calls.\nThat’s a great idea as the co
mmunity can learn what is currently happening in the Ditto project and the
committers can learn how the community uses Ditto and what they are maybe
missing.\n\nWe will start with a 4 weekly recurrence and see if we have d
emand for more regular calls.\n\n\nJoin Zoom Meeting\nhttps://eclipse.zoom
.us/j/937598490\n\nMeeting ID: 937 598 490\n\nOne tap mobile\n+16468769923
\,\,937598490# US (New York)\n+16699006833\,\,937598490# US (San Jose)\n\n
Dial by your location\n +1 646 876 9923 US (New York)\n +1 6
69 900 6833 US (San Jose)\n +1 647 558 0588 Canada\n +33 1 7
037 2246 France\n +33 1 7037 9729 France\n +33 7 5678 4048 F
rance\n +49 30 3080 6188 Germany\n +49 30 5679 5800 Germany\
n +49 69 7104 9922 Germany\n +44 203 481 5237 United Kingdom
* application of the ServiceLoader in OSGi is not ensured or tested as we don't assume that someone wants to use CBOR backed serialization when e.g. using the Java Ditto-Client
* some "breaking" changes to ditto-json can be tolerated as the affected APIs can be treated as "Ditto backend internal" APIs required to apply CBOR serialization
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
DerSchwilk
pushed a commit
to bosch-io/ditto
that referenced
this issue
Sep 10, 2020
Merge pull request eclipse#793 from bosch-io/bugfix/ditto-json-cbor-d…
…
357882c
…ependencies
Issue eclipse#790 split up ditto-json and ditto-json-cbor
DerSchwilk
pushed a commit
to bosch-io/ditto
that referenced
this issue
Sep 10, 2020
Issue eclipse#790 split up ditto-json and ditto-json-cbor
…
59f319b
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
[ditto-dev] Logos of Ditto users on website,
Jaeckle Thomas (INST/ECS1)
[ditto-dev] Release announcement of Eclipse Ditto 0.8.0,
Jaeckle Thomas (INST/ECS1)
[ditto-dev] Release Review for Ditto 0.8.0,
Jaeckle Thomas (INST/ECS1)
[ditto-dev] CFP Deadline July 16 - All Things IoT @ EclipseCon Europe,
Roxanne Joncas
[ditto-dev] PMC Approval required for Committer Election for Florian Fendt on Eclipse Ditto,
emo
[ditto-dev] Committer Election for Florian Fendt on Eclipse Ditto has started,
emo
[ditto-dev] Eclipse Ditto logo crowdsourcing,
Jaeckle Thomas (INST/ECS1)
Re: [ditto-dev] Eclipse Ditto logo crowdsourcing,
Jaeckle Thomas (INST/ECS1)
Re: [ditto-dev] Eclipse Ditto logo crowdsourcing,
Glocker Gerald (INST/ECS1)
Welcome to ditto-dev,
portal on behalf of emo
Mail converted by MHonArc
Back to the top
Eclipse Foundation
About Us
Contact Us
thjaeckle
added this to the 1.1.0 milestone
Dec 13, 2019
Copy link
Contributor
w4tsn
commented
Dec 18, 2019
This is a wonderful new feature - I'm currently caching things on the micro-service level to get meta information such as the definition field when processing incoming messages based on information from the model. This would make it much more easier!
👍
3
Copy link
Contributor
Author
thjaeckle
commented
Dec 18, 2019
Cool, nice to hear that :)
thjaeckle
mentioned this issue
Jan 2, 2020
Support for GraphQL
For Things we know the ID of, we can simply query them by their ID:
curl -u ditto:ditto -X GET 'http://localhost:8080/api/1/things/org.eclipse.ditto:fancy-car'
# if you have python installed, that's how to get a prettier response:
curl -u ditto:ditto -X GET 'http://localhost:8080/api/1/things/org.eclipse.ditto:fancy-car' | python -m json.tool
Querying one specific state value
The created API for our Thing also provides HTTP endpoints for each attribute and feature property.
That way we can for example just retrieve the cur_speed of our fancy car:
curl -u ditto:ditto -X GET 'http://localhost:8080/api/1/things/org.eclipse.ditto:fancy-car/features/transmission/properties/cur_speed'
Updating one specific state value
We can just as easy use the HTTP API to update one attribute or feature property, e.g. update the cur_speed to 77:
curl -u ditto:ditto -X PUT -d '77' 'http://localhost:8080/api/1/things/org.eclipse.ditto:fancy-car/features/transmission/properties/cur_speed'
Searching for all Things
When we lost the overview which Things we have already created, we can use the search HTTP endpoint,
e.g. searching all Things with the same manufacturer named "ACME":
curl -u ditto:ditto -X GET 'http://localhost:8080/api/1/search/things?filter=eq(attributes/manufacturer,"ACME")'
Tags:
getting_started
©2020 Eclipse Ditto.
Site last generated: Nov 17, 2020
> Privacy Policy
> Terms of Use
> Copyright Agent
Can't see Captcha Image · Issue #31 · eclipse/ditto-examples · GitHub
Jul 30, 2020
The suggested header syntax has one major drawback.
Assuming a command modifies a complete thing (ModifyThing command) like the following:
{
"topic": "org.eclipse.ditto/thing-1/things/twin/commands/modify",
"headers": {
"ditto-metadata:issuedAt": "2020-06-09T14:29:00Z",
...
},
"path": "/",
"value": {
"features": {
"lamp": {
"properties": {
"on": false,
"color": {
"r": 255,
"g": 255,
"b": 0
}
\n +44 203 966 3809 United Kingdom\n +44 131 460 1196 United
Kingdom\n +44 203 051 2874 United Kingdom\n +41 22 518 89 7
8 Switzerland\n +41 31 528 09 88 Switzerland\n +41 43 210 70
42 Switzerland\n +46 8 4468 2488 Sweden\n +46 850 539 728 S
weden\n +45 32 71 31 57 Denmark\n +45 89 88 37 88 Denmark\n
+31 20 241 0288 Netherlands\n +31 20 794 0854 Netherlands\nM
eeting ID: 937 598 490\nFind your local number: https://eclipse.zoom.us/u/
afBu7G4IA\n\n\n\n\nBest regards\n\nThomas Jaeckle\n\nEngineering Cloud Ser
vices 1 Bosch IoT Things (INST/ECS1)\nBosch Software Innovations GmbH | Zi
egelei 7 | 88090 Immenstaad | GERMANY | www.bosch-si.com<http://www.bosch-
si.com>\n\n\nSitz: Berlin\, Registergericht: Amtsgericht Charlottenburg\;
HRB 148411 B\nAufsichtsratsvorsitzender: Dr.-Ing. Thorsten Lücke\; Gesch
äftsführung: Dr. Stefan Ferber\, Michael Hahn\, Dr. Aleksandar Mitrovic\
n
RRULE:FREQ=WEEKLY;COUNT=100;INTERVAL=4;BYDAY=MO;WKST=MO
UID:040000008200E00074C5B7101A82E00800000000F0F074979A9BD501000000000000000
010000000996D4E517624684A90D5D9606599BF47
SUMMARY;LANGUAGE=de-DE:Abgesagt: Eclipse Ditto community call
DTSTART;TZID=W. Europe Standard Time:20191125T160000
DTEND;TZID=W. Europe Standard Time:20191125T170000
CLASS:PUBLIC
PRIORITY:1
DTSTAMP:20201119T112249Z
TRANSP:TRANSPARENT
STATUS:CANCELLED
* abstraction is done via a java.util.ServiceLoader
* application of the ServiceLoader in OSGi is not ensured or tested as we don't assume that someone wants to use CBOR backed serialization when e.g. using the Java Ditto-Client
* some "breaking" changes to ditto-json can be tolerated as the affected APIs can be treated as "Ditto backend internal" APIs required to apply CBOR serialization
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
DerSchwilk
pushed a commit
to bosch-io/ditto
that referenced
this issue
Sep 10, 2020
Merge pull request eclipse#793 from bosch-io/bugfix/ditto-json-cbor-d…
…
6ae7bc3
…ependencies
Issue eclipse#790 split up ditto-json and ditto-json-cbor
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Assignees
No one assigned
Labels
bug
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
Donate
Governance
Logo and Artwork
Board of Directors
Legal
Privacy Policy
Terms of Use
Copyright Agent
Eclipse Public License
Legal Resources
Useful Links
Report a Bug
Documentation
How to Contribute
Mailing Lists
Forums
Marketplace
Other
IDE and Tools
Community of Projects
Working Groups
Research@Eclipse
Report a Vulnerability
Service Status
#585
Closed
Copy link
Contributor
BobClaerhout
commented
Jan 13, 2020
Nice feature! We are looking forward to this as well!
👍
1
thjaeckle
self-assigned this
Jan 31, 2020
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: Enhanced Ditto Protocol messages by "extra" field.
…
a1a008d
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
> Legal
> License
> Report a Vulnerability
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
Learning Lab
}
}
}
}
}
Then the value of "issuedAt" would be applied to all feature properties, i. e. on, r, g, b.
This way it is impossible to set a metadata value exclusively at the root level (/), i. e. the thing itself.
How about a syntax which allows to determine the level more specifically?
Example one:
{
"topic": "org.eclipse.ditto/thing-1/things/twin/commands/modify",
"headers": {
"ditto-metadata:issuedAt": "2020-06-09T14:29:00Z",
...
},
"path": "/",
"value": {
"features": {
"lamp": {
"properties": {
"on": false,
"color": {
"r": 255,
"g": 255,
SEQUENCE:6
LOCATION;LANGUAGE=de-DE:https://eclipse.zoom.us/j/937598490
X-MICROSOFT-CDO-APPT-SEQUENCE:6
X-MICROSOFT-CDO-OWNERAPPTID:-1357924381
X-MICROSOFT-CDO-BUSYSTATUS:FREE
X-MICROSOFT-CDO-INTENDEDSTATUS:FREE
X-MICROSOFT-CDO-ALLDAYEVENT:FALSE
X-MICROSOFT-CDO-IMPORTANCE:2
X-MICROSOFT-CDO-INSTTYPE:1
X-MICROSOFT-DONOTFORWARDMEETING:FALSE
X-MICROSOFT-DISALLOW-COUNTER:FALSE
END:VEVENT
END:VCALENDAR
Prev by Date:
[ditto-dev] Seeking guidance re: Ditto, Hono, and Cloud2edge package
Previous by thread:
[ditto-dev] Seeking guidance re: Ditto, Hono, and Cloud2edge package
Index(es):
Date
Thread
Back to the top
Eclipse Foundation
About Us
Contact Us
Projects
None yet
Milestone
1.2.1
Linked pull requests
Successfully merging a pull request may close this issue.
Issue #790 split up ditto-json and ditto-json-cbor
3 participants
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
Copyright © Eclipse Foundation, Inc. All Rights Reserved.
Back to the top
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: Add Payload.toBuilder() and test it.
…
7a5ccf2
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
thjaeckle
added a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: fixed ImmutablePayloadTest by fixing ImmutablePayl…
…
cfcde5c
…oadBuilder MessagePath copying
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
thjaeckle
added a commit
to bosch-io/ditto
Fixed typos in readme by joosdavid · Pull Request #14 · eclipse/ditto-examples · GitHub
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
Jump to
↵
"b": 0
}
}
}
}
}
}
Example one is interpreted in a way to set the value of "issuedAt" only at the root level (path /).
Example two:
{
"topic": "org.eclipse.ditto/thing-1/things/twin/commands/modify",
"headers": {
"ditto-metadata:*/issuedAt": "2020-06-09T14:29:00Z",
...
},
"path": "/",
"value": {
"features": {
"lamp": {
"properties": {
"on": false,
"color": {
"r": 255,
"g": 255,
"b": 0
Donate
Governance
Logo and Artwork
Board of Directors
Legal
Privacy Policy
Terms of Use
Copyright Agent
Eclipse Public License
Legal Resources
Useful Links
Report a Bug
Documentation
How to Contribute
Mailing Lists
Forums
Marketplace
Other
IDE and Tools
Community of Projects
Working Groups
Research@Eclipse
Report a Vulnerability
Service Status
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: fixed that DittoTestSystem was not included in tes…
…
d263048
…t-jar of ditto-signals-base
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
thjaeckle
added a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: reviewed facade - renamed, moved out of separate p…
…
410cbad
…ackage, removed initialization of roundtrip facade in interface
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto-examples
Watch
16
Star
35
Fork
20
Code
Issues
2
Pull requests
5
Actions
Projects
}
}
}
}
}
}
In example two the asterisk implies that the value of "issuedAt" should be applied to all the affected JSON leaves, in this case on, r, g and b.
Copy link
Contributor
thjaeckle
commented
Jul 30, 2020
How about a syntax which allows to determine the level more specifically?
I like that concept 👍
jufickel-b
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Jul 31, 2020
Issue eclipse#680: Some refactoring to make adding metadata via Ditto…
Copyright © Eclipse Foundation, Inc. All Rights Reserved.
Back to the top
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
_
Sign in to start talking
this issue
Feb 3, 2020
Issue eclipse#561: Add configurable dynamic loading of thing-enrichin…
…
a550c9d
…g facade providers.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: add actorsystem parameter to enrichment facade pro…
…
aa522f2
…viders.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Learning Lab
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
Jump to
0
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
New issue
Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
…
79c7da6
…Headers more generic (WIP).
* Moved Metadata and its related types to base model as metadata affects all entities and not only things.
* Adjusted some Javadoc comments.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch.io>
Copy link
Contributor
Author
JulianFeinauer
commented
Jul 31, 2020
@jufickel-b thanks, this is a neat idea. From an application perspective I would always prefer the second example as it saves some algorithmic complexity. But just to assure.. in both cases the algorithm would hold and stay consistend
check if there is an issuedAt at your node
if not, go to parent and repeat until you found one
Or can there be a sequence of messages that leads to a situation where aboves algorithm would yield a wrong response? I'm not sure ATM.
jufickel-b
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Issue eclipse#561: Add configurable dynamic loading for message-enric…
…
616dc0e
…hment in connectivity.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
thjaeckle
added a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: use AbstractGraphActor as baseclass for MessageMap…
…
bdf5e9a
…pingProcessorActor in order to process OutboundSignal messages in a streamed way; enhanced AbstractGraphActor by generifying the message classes it handles
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
thjaeckle
added a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: fixed javadoc errors
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto-examples
Watch
16
Star
35
Fork
20
Code
Issues
2
Pull requests
5
Actions
Pick a username
Email Address
Password
Sign up for GitHub
By clicking “Sign up for GitHub”, you agree to our terms of service and
privacy statement. We’ll occasionally send you account related emails.
Already on GitHub?
Sign in
to your account
Jump to bottom
Can't see Captcha Image
#31
Closed
danielanghell opened this issue
Mar 29, 2020
· 4 comments
Closed
Can't see Captcha Image
#31
danielanghell opened this issue
Mar 29, 2020
· 4 comments
Comments
Copy link
Aug 3, 2020
Issue eclipse#680: Added unhandled case to `MetadataFromEvent` to mak…
…
7c2b235
…e unit tests work again.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch.io>
thjaeckle
added this to the 1.2.0 milestone
Aug 3, 2020
jufickel-b
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Aug 7, 2020
Issue eclipse#680: Removed unused parameter 'resourcePath' from metho…
…
2afc143
…d for setting metadata to ThingBuilder.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch.io>
jufickel-b
added a commit
to JulianFeinauer/ditto
…
3c369e1
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: Ensure that extra fields are available to WebSocke…
…
710cb04
…t and SSE subscriptions and connections.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: Fixed bug in `ThingsSseRouteBuilder` where "fields…
…
32e469a
Projects
0
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
New issue
Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
Quote reply
danielanghell
commented
Mar 29, 2020
Regarding the SmartCoffeeMachine, I am trying to brew a coffee but it doesn't happen because it doesn't pop up any captcha code. Obviously, I have created the twin and I have also connected to it. Heating up water tank and the reverse action work fine.
I can see that the PUT request is sent and also de JSON file is arriving at the machine, but since I cannot solve any captcha, I receive a 408 Request Timeout.
Copy link
Contributor
ffendt
commented
Mar 30, 2020
Hi @danielanghell,
can you please check if the browser console (F12) is printing any errors after sending the "Go make me a coffee" message is sent? This sounds like it might be a JavaScript bug in the example.
Copy link
Author
danielanghell
commented
Mar 30, 2020
Here is the error highlighted while trying to "make a coffee".
ffendt
added a commit
that referenced
this issue
Aug 7, 2020
Issue eclipse#680: Deleted `MetadataHandler` as it is not required an…
…
7a03690
…ymore.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch.io>
jufickel-b
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Aug 7, 2020
Issue eclipse#680: Made `DittoHeaders` and `DittoHeadersBuilder` awar…
…
74af61f
…e of metadata.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch.io>
jufickel-b
added a commit
to JulianFeinauer/ditto
that referenced
this issue
…" query parameter was not evaluated.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: Some refactoring around `AbstractGraphActor`:
…
c72cadf
* Use DittoDiagnosticLoggingAdapter for logging.
* Extended static factory method for getting counter in `DittoMetrics` to be able to set tags directly to avoid superfluous object creation. Extended `KamonCounter` accordingly.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561 Replace 'thing enrich...' by 'signal enrichment' ev…
…
571d2e1
Pick a username
Email Address
Password
Sign up for GitHub
By clicking “Sign up for GitHub”, you agree to our terms of service and
privacy statement. We’ll occasionally send you account related emails.
Already on GitHub?
Sign in
to your account
Jump to bottom
Fixed typos in readme
#14
Merged
thjaeckle
merged 1 commit into
eclipse:master
from
bosch-io:feature/payload-mapping-testrunner
Apr 30, 2019
Merged
Fixed typos in readme
#14
thjaeckle
merged 1 commit into
to bosch-io/ditto-examples
that referenced
this issue
Apr 2, 2020
eclipse#31 Fix bug where the SmartCoffeeApp tried to deserialize a JS…
…
cd488dc
…ON message twice.
Signed-off-by: Florian Fendt <Florian.Fendt@bosch.io>
ffendt
mentioned this issue
Apr 2, 2020
Deserialize JSON only once
#34
Merged
Copy link
Contributor
ffendt
commented
Apr 2, 2020
Hi @danielanghell
Aug 7, 2020
Issue eclipse#680: Fixed script for building Docker images locally.
…
7ead8b3
Additionally made it possible to set proxy.
Adjusted Ditto main README accordingly.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch.io>
Copy link
Contributor
jufickel-b
commented
Aug 11, 2020
@JulianFeinauer I think so, too. I cannot think of a message sequence which disturbs the algorithm.
Copy link
Contributor
jufickel-b
commented
Aug 11, 2020
With commit 74af61f an implementation of my suggestion dated 2020-07-30 exists.
Tests showed however, that there is a problem: HTTP headers are not allowed to contain slashes or colons. Thus the syntax of the metadata header should be changed.
I already had a discussion with @thjaeckle regarding this issue. We think that it would be best to change the syntax of metadata header as follows:
Header name: metadata as the prefix ditto- implies that it cannot be set externally but only internally by Ditto itself.
Header value: PATH=VALUE where PATH is either a regular JSON Pointer or a "wildcard path" like for example /*/issuedAt. VALUE is a valid JSON value. Multiple metadata key-value pairs are separated by a comma ,.
…erywhere; add null checks and tests in GatewyByRoundtripProvider; remove unused imports.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: Reuse SignalEnrichmentConfig in connectivity; move…
…
0aa2709
… mapping stream settings to MappingConfig.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: implement signal enrichment for connectivity.
…
267411d
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
eclipse:master
from
bosch-io:feature/payload-mapping-testrunner
Apr 30, 2019
Conversation
0
Commits
1
Checks
0
Files changed
Conversation
Copy link
Quote reply
Contributor
joosdavid
commented
Apr 16, 2019
Signed-off-by: David Joos david.joos@bosch-si.com
Fixed typos in readme
…
Loading status checks…
c90ade5
Signed-off-by: David Joos <david.joos@bosch-si.com>
sorry for letting you wait. The javascript app tried to parse the received JSON twice (which I fixed with #34). Thanks for letting us know about this bug!
Can you please pull the examples again and try if it works now on your side, too?
Copy link
Author
danielanghell
commented
Apr 2, 2020
Hello @ffendt,
thank you for your help and kindness. Now it works fine!
danielanghell
closed this
Apr 2, 2020
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Assignees
No one assigned
Labels
None yet
Projects
None yet
Milestone
eclipse/ditto - Gitter
eclipse/ditto - Gitter
A HTTP header for setting metadata could look as follows – the leading slash (/) of the paths is optional:
metadata: /*/issuedAt="2020-06-09T14:29:00Z",/color/r/someCounter=23
This approach has the advantage that metadata could become a well-known DittoHeaderDefinition as it is no longer just a prefix.
@JulianFeinauer what do you think about this topic?
Copy link
Contributor
Author
JulianFeinauer
commented
Aug 11, 2020
Thanks for all the effort you put into the topic @jufickel-b and @thjaeckle !
The suggestion is fine for me although we could probably look for a well known format to transport the list of metadata like JSON to make it easier (from an application perspective) to parse and serialize the information.
WDYT?
Copy link
Contributor
jufickel-b
commented
Aug 11, 2020
We discussed this, too and this is also fine. If the header value was a JSON object the example would look like
The advantage, like you already mentioned, is a well-known format (JSON) which makes it easier for applications to handle.
A possible drawback could be that the header value could be confused with the effective Metadata object of the thing (_metadata).
Should we go with JSON?
Copy link
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: Add exception for signal enrichment failure.
…
208ae35
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Feb 3, 2020
Issue eclipse#561: Move SignalEnrichmentConfig under ConnectivityConfig.
…
5ca6feb
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
thjaeckle
pushed a commit
to bosch-io/ditto
that referenced
this issue
Hide details
View details
thjaeckle
merged commit 4e930e6
into
eclipse:master
Apr 30, 2019
1 check passed
1 check passed
eclipsefdn/eca
The author(s) of the pull request is covered by necessary legal agreements in order to proceed!
Details
thjaeckle
deleted the
bosch-io:feature/payload-mapping-testrunner
branch
Apr 30, 2019
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Reviewers
No reviews
Assignees
No milestone
Linked pull requests
Successfully merging a pull request may close this issue.
None yet
2 participants
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
eclipse/ditto - Gitter
eclipse/ditto - Gitter
Add InfluxDB example by damian-gallo · Pull Request #39 · eclipse/ditto-examples · GitHub
Contributor
Author
JulianFeinauer
commented
Aug 11, 2020
From a users perspective definetly JSON but I get your point.
But I think there are few alternatives if we have multiple informations in one header fields payload, or?
Copy link
Contributor
jufickel-b
commented
Aug 11, 2020
Yes, indeed. So JSON it is :-)
Copy link
Contributor
Yannic92
commented
Aug 12, 2020
I think we could run into problems with the single JSON-Object as Metadata value.
Our JSON parsing will parse this meta data :
To the following JSON Object. After this parsing we can't get the initial path /features/lamp/properties/color/r anymore
{
Feb 3, 2020
Issue eclipse#561: Enrich signals for websocket.
…
8dbde2e
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
349 hidden items
Load more…
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Fixed unit test by adding missing mocks.
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
97d346a
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
No one assigned
Labels
None yet
Projects
None yet
Milestone
No milestone
Linked issues
Successfully merging this pull request may close these issues.
None yet
2 participants
Add this suggestion to a batch that can be applied as a single commit.
This suggestion is invalid because no changes were made to the code.
Suggestions cannot be applied while the pull request is closed.
Suggestions cannot be applied while viewing a subset of changes.
Only one suggestion per line can be applied in a batch.
Add this suggestion to a batch that can be applied as a single commit.
Applying suggestions on deleted lines is not supported.
You must change the existing code in this line in order to create a valid suggestion.
Outdated suggestions cannot be applied.
This suggestion has been applied or marked resolved.
Suggestions cannot be applied from pending reviews.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Trending
Learning Lab
"features": {
"lamp": {
"properties": {
"color": {
"r": {
"issuedAt": "someTimeStamp",
"issuedBy": {
"name": "me",
"mail": "me@mail.com"
}
}
}
}
}
}
}
Therefore I suggest a format like this:
meta-data: [{
"path" : "/features/lamp/properties/color/r":
}]
👍
2
Copy link
Contributor
jufickel-b
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Remove unused config ditto.connectivity.mapping.si…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
579ec22
…gnal-enrichment-provider-path.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: DADR-0004: fix typo & describe smart update.
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Suggestions cannot be applied on multi-line comments.
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
eclipse/ditto - Gitter
eclipse/ditto - Gitter
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
All GitHub
↵
Jump to
↵
commented
Aug 12, 2020
@Yannic92 this is exactly the behaviour I experienced while playing around.
Your suggestion seems to be a reasonable solution.
jufickel-b
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Aug 13, 2020
Issue eclipse#680: Refactored syntax of metadata for DittoHeaders acc…
…
0dc0920
…ording to [discussion on Github](eclipse#680 (comment)).
Metadata is now a well-known Ditto header and not just a prefix of a header name.
The metadata header name does not have the prefix 'ditto-' anymore because setting those externally is forbidden by Ditto.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch.io>
jufickel-b
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Aug 18, 2020
Issue eclipse#680: Fixed bug in `AbstractDittoHeadersBuilder` where a…
eclipse/ditto - Gitter
Learn about signing commits
e7bdd34
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Swap target address enrichment and filtering secti…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
669823e
…ons.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Emulated self type in `AbstractBuilder` and furthe…
eclipse/ditto - Gitter
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
eclipse/ditto - Gitter
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
ditto-clients/DittoClientUsageExamples.java at master · eclipse/ditto-clients · GitHub
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
_
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
_
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto-examples
Watch
16
Star
35
Fork
20
Code
Issues
2
Pull requests
5
Actions
Projects
0
…
97229c2
… call to `putHeaders` might have discarded already set metadata.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch.io>
Copy link
Contributor
jufickel-b
commented
Aug 18, 2020
With commit JulianFeinauer@97229c2 we have a working state for setting metadata via headers.
A valid HTTP header of this implementation looks like for example (formatted for better readability)
metadata: [
{
"key":"/features/lamp/properties/color/r",
},
{
"key":"*/",
"value":"bar"
}
]
I wonder how one could get rid of unused metadata, as headers only allow to set metadata. An already working solution could be to set the value to the null literal at an appropriate level. What do you think?
Still missing is proper documentation of the feature in ditto-documentation. @JulianFeinauer do you want to add some?
Copy link
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
8dd34cd
…r minor improvements.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Fix a Sonar finding.
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
eclipse/ditto - Gitter
eclipse/ditto - Gitter
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
Skip to content
Sign up
Why GitHub?
Features →
Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile
Customer stories →
Security →
Team
Enterprise
Explore
Explore GitHub →
Learn & contribute
Topics
Collections
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
_
Jens Reimann
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
_
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
New issue
Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
Pick a username
Email Address
Password
Sign up for GitHub
Contributor
Author
JulianFeinauer
commented
Aug 18, 2020
First, thanks for your strong support @jufickel-b and @thjaeckle . I will add documentation and I would be fine with deleting them via "setting" them to null.
👍
1
thjaeckle
changed the title
Support for last-updated timestamp in features / properties
Support for adding arbitrary _metadata for features / properties
Aug 24, 2020
Copy link
Contributor
thjaeckle
commented
Aug 24, 2020
I adjusted the title of the issue as this turned out to be a more generic approach (which I highly appreciate 👍)
thjaeckle
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
7b9e624
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: fixed NPE
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
d228947
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
eclipse/ditto - Gitter
eclipse/ditto - Gitter
eclipse/ditto - Gitter
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
Trending
Learning Lab
Open source guides
Connect with others
Events
Community forum
GitHub Education
GitHub Stars program
Marketplace
Pricing
Plans →
Compare plans
Contact Sales
Nonprofit →
Education →
In this repository
All GitHub
↵
Jump to
↵
No suggested jump to results
In this repository
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
_
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
_
Jens Reimann
@ctron
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
_
Alexander Wellbrock
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
_
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
_
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
By clicking “Sign up for GitHub”, you agree to our terms of service and
privacy statement. We’ll occasionally send you account related emails.
Already on GitHub?
Sign in
to your account
Jump to bottom
Add InfluxDB example
#39
Merged
thjaeckle
merged 1 commit into
eclipse:master
from
damian-gallo:add_influxdb_example
Aug 3, 2020
Merged
Add InfluxDB example
#39
thjaeckle
merged 1 commit into
eclipse:master
from
damian-gallo:add_influxdb_example
Aug 3, 2020
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Aug 25, 2020
eclipse#680 review: renamed DittoHeaderDefinition key from "metadata"…
…
cb7475d
… to "put-metadata" to make more explicit was is done with this header's content
* added some missing and adjusted other javadocs
* added some missing @SInCE annotations
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
thjaeckle
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Aug 25, 2020
eclipse#680: fixed open issues mentioned in PR
…
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Jens Reimann
@ctron
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
eclipse/ditto - Gitter
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: enhanced Message and MessageBuilder in model with …
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
b6bd41f
…"extra" fields
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Fix review findings.
…
eclipse/ditto - Gitter
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Jens Reimann
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
_
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
All GitHub
↵
Jump to
↵
In this repository
All GitHub
↵
Jump to
↵
Sign in
Sign up
eclipse
/
ditto-clients
Watch
14
Star
16
Fork
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
my gut says that it could already work - feedback is welcome here ^^
_
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
Conversation
1
Commits
1
Checks
0
Files changed
Conversation
Copy link
Quote reply
Contributor
damian-gallo
commented
Aug 1, 2020
Signed-off-by: gallodamian93 gallodamian93@gmail.com
🎉
1
Add InfluxDB example
…
Loading status checks…
0bab7f4
Signed-off-by: gallodamian93 <gallodamian93@gmail.com>
thjaeckle
eclipse/ditto - Gitter
b2c8b78
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
thjaeckle
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Aug 25, 2020
eclipse#680: fixed Javadoc error
…
3a53e36
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
This was referenced Aug 25, 2020
Retrieve thing metadata when not retrieving complete thing
#772
Open
Implicit metadata creation on JSON leaves
#778
Open
Make is possible to delete metadata from a thing
eclipse/ditto - Gitter
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
cefac72
- *SignalEnrichmentProvider are now abstract classes and their
ExtensionId private static inner classes.
- Inlined MessageMappingProcessorActor.getSignalEnrichmentFacade.
- Made MockConciergeForwarderActor package-private.
- Stop loading enrichment provider in connectivity root actor.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: fixed enrichment error reporting via Websocket - h…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
_
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
9
Code
Issues
12
Pull requests
2
Actions
Projects
0
Security
Insights
More
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Permalink
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
approved these changes
Aug 3, 2020
View changes
Copy link
Quote reply
Contributor
thjaeckle
left a comment
LGTM 👍
Thank you very much for this contribution.
Highly appreciated.
👍
1
Hide details
View details
thjaeckle
merged commit 40a4a92
into
eclipse:master
Aug 3, 2020
1 check passed
1 check passed
eclipsefdn/eca
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
#779
Open
thjaeckle
closed this
in
#745
Aug 28, 2020
thjaeckle
removed
the
in progress
label
Aug 31, 2020
thjaeckle
mentioned this issue
Sep 3, 2020
Provide documentation for _metadata feature
#785
Closed
JulianFeinauer
Where communities thrive
Join over
1.5M+ people
Join over
100K+ communities
Free
without limits
Create
your own community Explore more communities
eclipse/ditto
Eclipse Ditto - Digital Twins for Eclipse IoT
People
Repo info
Activity
Thomas Jaeckle
@thjaeckle
Ditto doesn't provide an HTTP endpoint which is able to consume thisIt however provides a WebSocket API which would be able to consume such messages:https://www.eclipse.org/ditto/httpapi-protocol-bindings-websocket.html
yes, it would .. (when authorization was also successful as prerequisite)
Ditto is able to process those message either via WebSocket or AMQP 1.0, AMQP 0.9.1, MQTT 3.1.1 or MQTT 5
Jens Reimann
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
_
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
2e8af86
…ad to be wrapped in a DittoProtocol message
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: fixed CriteriaVisitor and its implementations by s…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
10bf3fd
…witching to List in the signature and deprecating old Stream based APIs
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
_
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
_
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
_
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
I'm good at breaking stuff I suppose :'D
_
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
no
_
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Dismiss
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up
GitHub is where the world builds software
Millions of developers and companies build, ship, and maintain their software on GitHub — the largest and most advanced development platform in the world.
Sign up for free
Dismiss
master
ditto-clients/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java
/
Jump to
Sign in to start talking
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
The author(s) of the pull request is covered by necessary legal agreements in order to proceed!
Details
damian-gallo
deleted the
damian-gallo:add_influxdb_example
branch
Aug 3, 2020
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Reviewers
thjaeckle
Assignees
No one assigned
Labels
None yet
Projects
None yet
Milestone
No milestone
Linked issues
Successfully merging this pull request may close these issues.
None yet
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
Alexander Wellbrock
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Sep 5, 2020
Issue eclipse#785 add documentation for the Ditto metadata feature (e…
…
74f36b7
…clipse#680).
DerSchwilk
pushed a commit
to bosch-io/ditto
that referenced
this issue
Sep 10, 2020
eclipse#680: fixed open issues mentioned in PR
…
4c17e1c
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
@ctron
ok … so if I would use WS, then it would work the same way?
Thomas Jaeckle
@thjaeckle
yes, you would just send this JSON into the established WS session
Jens Reimann
@ctron
but that would mean that it shouldn't be too difficult to create an HTTP endpoint which would do the same.
Thomas Jaeckle
@thjaeckle
true .. however FMPOV that is the domain of Hono - Ditto would not want to "connect" devices directly to its HTTP APIs - that's not what Ditto is build for (handling millions of devices sending data via HTTP)its APIs are build for backend or mobile applications which use several factors less of connections
Jens Reimann
@ctron
No it would connect to millions of devices, but would be a Knative event sink … which effectively is an HTTP endpoint, that gets called when a new message arrives
similar to kafka, AMQP or MQTT notifying you of a new message
Thomas Jaeckle
@thjaeckle
hm, ok .. it's the first time I hear about Knative event sink .. let me google that :D
Jens Reimann
@ctron
take your time :) … I will try out the WS approach … thx for your quick help
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
Mar 14, 2020
Issue eclipse#561: Added revoked subjects to DittoHeaders.
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
11a44b6
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Add DADR-0005-semantic-versioning.md.
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
7008fe9
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
Code definitions
Code navigation index up-to-date
Go to file
Go to file
T
Go to line
L
Go to definition
R
Copy path
Cannot retrieve contributors at this time
executable file
799 lines (713 sloc)
37.2 KB
Raw
Blame
/*
* Copyright (c) 2019 Contributors to the Eclipse Foundation
*
* See the NOTICE file(s) distributed with this work for additional
* information regarding copyright ownership.
*
* This program and the accompanying materials are made available under the
2 participants
Add this suggestion to a batch that can be applied as a single commit.
This suggestion is invalid because no changes were made to the code.
Suggestions cannot be applied while the pull request is closed.
Suggestions cannot be applied while viewing a subset of changes.
Only one suggestion per line can be applied in a batch.
Add this suggestion to a batch that can be applied as a single commit.
Applying suggestions on deleted lines is not supported.
You must change the existing code in this line in order to create a valid suggestion.
Outdated suggestions cannot be applied.
This suggestion has been applied or marked resolved.
Suggestions cannot be applied from pending reviews.
Suggestions cannot be applied on multi-line comments.
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
DerSchwilk
pushed a commit
to bosch-io/ditto
that referenced
this issue
Sep 10, 2020
eclipse#680: fixed Javadoc error
…
e67ac84
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
DerSchwilk
pushed a commit
to bosch-io/ditto
that referenced
this issue
Sep 10, 2020
eclipse#680: fixed open issues mentioned in PR
…
72edc57
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
Alexander Wellbrock
@lionax_gitlab
Hey there, I want to discuss the topic around eclipse/ditto#682 - Add custom HTTP REST API facades wrapping Ditto message commandsI've spent a couple more hours on thinking about a vorto-ditto eco-system and what role the operations in vorto play. I've come to this: if I've a fairly simple request for simply altering properties but I want the device to handle it, before it's updated in ditto I'll make use of the ditto commands API and it's specification. If it's something more complex than that, like turning machines on or off or changing state of a machinary I'll want to use messages. Messages will be specified in vorto as operations. That way I get a nice API documentation out of vorto. As a follow up on #682 I was wondering if it wouldn't make big sense to be able to do several things in ditto with this:
Provide / Query (Swagger) API Documentation for a Thing (or Micro-Service in that regard) based on the Vorto Model (Operations at least)
Provide HTTP REST API Facade for those Operations
Basically I'd operations (and maybe events while we are at it) to seemingly integrate with ditto's protocol as an addon such that it becomes transparent to the user and more streamlined how to work with things in (and micro-services attached to) ditto.What do you think?
Alexander Wellbrock
@lionax_gitlab
Btw. the "quickest" work-around so far would be to have a docs-service which listens to the messages/docs topic and returns a swagger document parsed from vorto models. A developer authenticated through a valid SSO could then just open any things messages/docs in the browser to take a look at a minimal API doc.
Thomas Jaeckle
@thjaeckle
post:
summary: Executes the switchOnFor on the device
description: |-
Switches the switchable on for a passed in duration, afterwards applying the previous 'on' configuration again
Send a message with the messageSubject `switchOnFor` **to** the feature specified by the featureId `Colored`
and thingId path parameter. The request body contains the message payload and the Content-Type header defines its type.
The API does not provide any kind of acknowledgement that the message was received by the feature.
The HTTP request blocks until a response to the message is available
or until the `timeout` is expired. If many clients respond to
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: fixed IllegalArgumentException in CachingSignalEnr…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
4a6ac94
…ichmentFacade for ThingEvent with empty resource path
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
* terms of the Eclipse Public License 2.0 which is available at
* http://www.eclipse.org/legal/epl-2.0
*
* SPDX-License-Identifier: EPL-2.0
*/
package org.eclipse.ditto.client;
import static java.util.concurrent.TimeUnit.SECONDS;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.io.InputStream;
import java.net.URL;
import java.time.OffsetDateTime;
import java.util.Arrays;
import java.util.Collection;
import java.util.Properties;
import java.util.Scanner;
import java.util.UUID;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
DerSchwilk
pushed a commit
to bosch-io/ditto
that referenced
this issue
Sep 10, 2020
eclipse#680: fixed Javadoc error
…
f90a89c
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch.io>
JulianFeinauer
added a commit
to JulianFeinauer/ditto
that referenced
this issue
Sep 16, 2020
Issue eclipse#785 add documentation for the Ditto metadata feature (e…
the issued message, the first response will complete the HTTP request.
In order to handle the message in a fire and forget manner, add
a query-parameter `timeout=0` to the request.
### Who
You will need `WRITE` permission on the root "message:/" resource, or at least
the resource `message:/outbox/messages/messageSubject`.
Such permission is managed within the policy which controls the access on the thing.
tags:
- Messages
parameters:
- $ref: '#/components/parameters/thingIdPathParam'
- $ref: '#/components/parameters/messageTimeoutParam'
responses:
'202':
description: |-
The message was sent but not necessarily received by the Feature
(fire and forget).
'400':
description: |-
The request could not be completed. Possible reasons:
* the `thingId` does not conform to the namespaced entity ID notation (see [Ditto documentation on namespaced entity IDs](https://www.eclipse.org/ditto/basic-namespaces-and-names.html#namespaced-id)).
* at least one of the defined path parameters is invalid.
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: don't handle "twin" ThingDeleted events - don't en…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
8a41e89
…rich them
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: added test for not enrichting "twin" ThingDeleted …
…
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
_
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
_
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Thomas Jaeckle
@thjaeckle
true, you are way too experienced in OSS ;-)
Sign in to start talking
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Jens Reimann
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;
import org.eclipse.ditto.client.changes.ChangeAction;
import org.eclipse.ditto.client.configuration.BasicAuthenticationConfiguration;
import org.eclipse.ditto.client.configuration.ClientCredentialsAuthenticationConfiguration;
import org.eclipse.ditto.client.configuration.DummyAuthenticationConfiguration;
import org.eclipse.ditto.client.configuration.MessagingConfiguration;
import org.eclipse.ditto.client.configuration.ProxyConfiguration;
import org.eclipse.ditto.client.configuration.TrustStoreConfiguration;
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
…
5548ffa
…clipse#680).
Corrections in basic-metadata.md and added changes to ditto-api-2.yml-Swagger Doc.
Signed-off-by: julian <j.feinauer@pragmaticminds.de>
JulianFeinauer
mentioned this issue
Sep 17, 2020
Feature/785 documentation metadata
#806
Merged
thjaeckle
added a commit
that referenced
this issue
Sep 23, 2020
Issue #785 add documentation for the Ditto metadata feature (#680).
…
dab6e4b
Corrections in basic-metadata.md and added changes to ditto-api-2.yml-Swagger Doc.
Signed-off-by: julian <j.feinauer@pragmaticminds.de>
yufei-cai
mentioned this issue
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'401':
description: The request could not be completed due to missing authentication.
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'403':
description: |-
The request could not be completed. Possible reasons:
* the API Token is missing or invalid
* the caller has insufficient permissions
content:
application/json:
schema:
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
_
Alexander Wellbrock
@lionax_gitlab
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
b2258c1
…events
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Renamed setter and getter for read revoked subject…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
aa8cf50
…s to include "read".
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
_
Alexander Wellbrock
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
_
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
_
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
@ctron
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Will do. Well I never expected that you will implement it for me ;-) …
Sign in to start talking
import org.eclipse.ditto.client.configuration.WebSocketMessagingConfiguration;
import org.eclipse.ditto.client.messaging.AuthenticationProvider;
import org.eclipse.ditto.client.messaging.AuthenticationProviders;
import org.eclipse.ditto.client.messaging.MessagingProvider;
import org.eclipse.ditto.client.messaging.MessagingProviders;
import org.eclipse.ditto.client.options.Options;
import org.eclipse.ditto.json.JsonFactory;
import org.eclipse.ditto.json.JsonFieldSelector;
import org.eclipse.ditto.json.JsonObject;
import org.eclipse.ditto.json.JsonValue;
import org.eclipse.ditto.model.base.common.HttpStatusCode;
import org.eclipse.ditto.model.base.exceptions.DittoRuntimeException;
import org.eclipse.ditto.model.base.json.JsonSchemaVersion;
import org.eclipse.ditto.model.messages.KnownMessageSubjects;
import org.eclipse.ditto.model.policies.Subject;
import org.eclipse.ditto.model.policies.SubjectId;
import org.eclipse.ditto.model.things.FeatureProperties;
import org.eclipse.ditto.model.things.Thing;
import org.eclipse.ditto.model.things.ThingBuilder;
import org.eclipse.ditto.model.things.ThingId;
import org.eclipse.ditto.model.things.ThingsModelFactory;
import org.eclipse.ditto.protocoladapter.JsonifiableAdaptable;
$ref: '#/components/schemas/AdvancedError'
'413':
$ref: '#/components/responses/messageTooLarge'
requestBody:
$ref: '#/components/requestBodies/ColorableLampSwitchOnForPayload'
...I don't see much benefit in Ditto providing this API when it is already available at the Vorto Repository.You can simply:a) retrieve a Thing's definitionb) build the Vorto Repo URL from itc) download the generated OpenAPI doc
Alexander Wellbrock
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Sep 30, 2020
Metadata is not deleted when thing parts are deleted
#829
Open
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Assignees
No one assigned
Labels
community-interest
enhancement
Projects
None yet
Milestone
1.2.0
Linked pull requests
Successfully merging a pull request may close this issue.
Feature/680 add metadata
4 participants
@lionax_gitlab
What I'd like to do, is to make vorto transparent here. My use-case also involves a private vorto repository with internal, customer related models. I'd like those models be retrievable through feature messages so the model access is restricted through ditto policies with ditto as a proxy. I'll probably write a micro-service for this purpose.The next thing is, that I'd like to call a /docs endpoint (via ditto messages) to retrieve a fully working Swagger Document (html which will directly render in the browser) and a /caps endpoint which will return a more machine-friendly interface specification like the swagger yml from above, which clients will use to generate stubs for implementation.Besides the operations and events defined in a vorto model for a feature there are additional infrastructure wide messaging-endpoints all things support which is realized by plugging in additional services via websockets and let them handle those operations. I'm not sure if I want to implement those in base-models via inheritance in vorto because that would require updates for alle inheriting models if something changes, I'd rather go with composite-pattern here. Which brings me to the though, wouldn't it be neat to have my micro-services be able to register at ditto for providing certain operations and events and then ultimately be able to retrieve a full API spec on a thing by doing a simple call to a thing? The API spec would then contain operations and events from vorto and from additional services. One endpoint would serve a developer doc for the browser, one a machine format for clients etc.I was thinking if it'd be a good addition for ditto to support such a thing in general, although it's somewhat a big topic and maybe just a little bit over-engineered :D
Thomas Jaeckle
@thjaeckle
agreed, that would add value to Ditto - I struggle a bit with the "api doc" per Thing as the YAML could get quite big and for Things with the same (root) definition the OpenAPI doc is always the same ... not very ideal (browser-)caching wisemaybe there could be a Ditto API e.g. /api/2/models/<definition> to which the model lookup of a single thing could redirector would you need/expect to have the resolved thingIds in the retruned OpenAPI doc for a concrete Thing?
Alexander Wellbrock
@lionax_gitlab
That's a really good point. If it is not implemented plain via ditto messages it might be more sensible and even more useful to have a model based approach here. The thingIds would only be required if there really are specific operations which are not bound to models, but then again this could be modelled differently so I don't see any benefit in having the IDs included.
Alexander Wellbrock
@lionax_gitlab
In terms of security as mentioned before some of the vorto models are IP and can't be exposed publicly. So in order to retrieve the spec for a things definition it has to be protected by dittos policy enforcement. So the most basic case is if I'm allowed to read a features definition I'm permitted to open it's API spec.If it should be more fine-grained, than the API doc would have to be stripped by the features and operations I'm not allowed to READ or WRITE to. As an example if a user is allowed to use the messaging API their are able to use the operations defined in the model anyway, so they should be able to see operations in the spec. Not so important, but wanted to mention it anyway.
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
Hello everyone, we currently have a problem in our project about the size limitation of a thing entity. In our case, the size can exceed 256 KB. How do you deal with this Problem? how is this problem typically solved in the context of Bosch IoT Things together with other services?
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
@lionax_gitlab
Ok, I'll open an issue
_
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
_
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
_
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Use domain model `AuthorizationSubject` for read g…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
83f8701
…ranted and revoked subjects in `DittoHeaders`.
* Use consistent naming for read authorization subjects.
* Deprecated String based `readSubject` methods in favor of new method.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Fix double-publishing of events generated by comma…
…
Unverified
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
_
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
import org.eclipse.ditto.protocoladapter.ProtocolFactory;
import org.eclipse.ditto.signals.commands.live.modify.CreateThingLiveCommandAnswerBuilder;
import org.eclipse.ditto.signals.commands.live.modify.ModifyFeaturePropertyLiveCommandAnswerBuilder;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import com.neovisionaries.ws.client.WebSocket;
/**
* Get the Ditto-Client up and running against different environments with typical use cases + load tests.
*/
public final class DittoClientUsageExamples {
private static final Logger LOGGER = LoggerFactory.getLogger(DittoClientUsageExamples.class);
private static final String PROPERTIES_FILE = "ditto-client-starter-local.properties"; // for local development
// private static final String PROPERTIES_FILE = "ditto-client-starter-sandbox.properties";
private static final String PROXY_HOST;
private static final String PROXY_PORT;
private static final String DITTO_ENDPOINT_URL;
private static final URL DITTO_TRUSTSTORE_LOCATION;
private static final String DITTO_TRUSTSTORE_PASSWORD;
private static final String DITTO_DUMMY_AUTH_USER;
private static final String DITTO_USERNAME;
private static final String DITTO_PASSWORD;
private static final String DITTO_OAUTH_CLIENT_ID;
Thomas Jaeckle
@thjaeckle
hi @kwh40for Ditto you can configure this size to whatever fits your needsEntity limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-limits.conf#L14just use the environment variable LIMITS_THINGS_MAX_SIZE for increasing the limit of Thing sizesoverall cluster size limits are defined here: https://github.com/eclipse/ditto/blob/master/services/utils/config/src/main/resources/ditto-akka-config.conf#L138overwrite the env variable REMOTE_MAX_FRAMESIZE etc. (also the lines below) to what you needI would however not increase this too much - there is a reason for limitations which is mainly memory consumption and throughput / lower latency .. and of course MongoDB document limitationsthere is a good reason why other IoT services like from AWS and Azure limit the size of their digital twins to even only 8kB
what if you really have such big things:
split them up in several
put data which is not intended to be included in the twin (like e.g. binary data) to external systems and just manage the link in the twin
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
_
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Ghost
@ghost~5ee9e84dd73408ce4fe7236d
@thjaeckle Thank you very much for your reply. It seems that the solution should firstly be based on the conceptual data model of the digital twins, and we should create a relationship between the digital twin and an "external system", where e.g. binary data is located, instead of directly inserting the whole binary data into the digital twin. But in this case, what kind of "external systems" could be implemented to store the large binary data? A web server or a local server? Are there any suggestions in the context of bosch iot suite?
Thomas Jaeckle
@thjaeckle
I would suggest using the cloud's ability to manage static/binary data ... on AWS for example, I would use S3 to put binary dataIf Ditto is self-hosted locally you have to think about something else of course :)
Alexander Wellbrock
@lionax_gitlab
I just tried to make a huge batch update of metadata to some of my things and noticed, that if I put a whole thing with a lot of metadata key/value pairs in the put-metadata header none of them get written, just an empty _metadata field appears. Is this intentional? Also if I instead only write all features to the PUT /features endpoint, the _metadata object contains an empty features object. I'd expect if I specify a metadata with key /features/lamp/properties/status/active and write a whole bunch of features including /features/lamp that this metadata get's written to the things metadata
_
pravussum
@pravussum
Hey there, I've got a question regarding concurrent updates. Suppose I have a twin and a connected device. A feature property of the twin is updated both by the device and another party at the same time. The device and the other party will receive an event, that the property has been updated, but they don't receive an event about their own updates (as far as I understand the docs). So how can they tell, which one "won"? Without their own event they cannot judge about the order, can they?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab I think metadata can only be written for JSON paths which were also included in the modify-command which piggy-backed the metadataso does the metadata structure reflect the thing structure you update?could you provide your API call?
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
0efa9db
…nds from connectivity.
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Use new method for getting read granted authorizat…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
168acdf
…ion subjects from DittoHeaders.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Thomas Jaeckle
@thjaeckle
now I think I start to get it ..well, a simple approach would be to accept Ditto Protocol JSON messages at a fixed endpoint (e.g. POST /api/2/protocol) and use the user provided authentication (may it be JWT or basic auth / pre-authenticated user)FMPOV this endpoint still would not have the capabilities to be invoked by e.g. millions of devices but would be intended to be invoked by other "backends" ..
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
and allows for a declarative deployment
Sign in to start talking
private static final String DITTO_OAUTH_CLIENT_SECRET;
private static final Collection<String> DITTO_OAUTH_SCOPES;
private static final String DITTO_OAUTH_TOKEN_ENDPOINT;
private static final String NAMESPACE;
private static final Properties CONFIG;
public static void main(final String... args) throws ExecutionException, InterruptedException {
final DittoClient client = DittoClients.newInstance(createMessagingProvider());
final DittoClient client2 = DittoClients.newInstance(createMessagingProvider());
if (shouldNotSkip("twin.examples")) {
final JsonifiableAdaptable jsonifiableAdaptable = ProtocolFactory.jsonifiableAdaptableFromJson(
JsonFactory.readFrom("{\n" +
" \"topic\": \"org.eclipse.ditto/xdk_53/things/twin/commands/modify\",\n" +
" \"headers\": {},\n" +
" \"path\": \"/\",\n" +
" \"value\": {\n" +
" \"thingId\": \"org.eclipse.ditto:xdk_53\",\n" +
" \"attributes\": {\n" +
" \"location\": {\n" +
" \"latitude\": 44.673856,\n" +
" \"longitude\": 8.261719\n" +
" }\n" +
" },\n" +
" \"features\": {\n" +
Alexander Wellbrock
@lionax_gitlab
What has changed is that now the metadata tree spans to the leafs / properties but there are only empty objects there
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
Thomas Jaeckle
@thjaeckle
@pravussum yes, events which were caused "by myself" are not send back to the same channel (e.g. websocket or a connection)I think currently finding that out which one "won" in your scenario will be hard to achive without additional API calls, yeswith additional API calls, the device or the other party could first retrieve the Things _revision, perform the update and if it gets an event with the revision increased by 2 it can assume that another party modified the Thing as well - but not (yet) with certainty that this update did affect the same property.We have an issue for tracking the _revision also on a property level here: #778Another thing which could help and I can think about as feature addition is to put the Thing's current _revision to the response's headers so that by consuming responses the device could find out at which revision the Thing now is with its modification applied ... there is not yet an issue for track that
Alexander Wellbrock
@lionax_gitlab
@pravussum hey there! I don't have an answer to your particular question but it raises another one: what if I have a process which "checks out" whole chunks of a thing, updates stuff and writes this back. Don't know if this is a serious use-case but in that case it would be good to have some kind of locking-mechanism so that clients can wait or something
Thomas Jaeckle
@thjaeckle
@lionax_gitlab you don't have to provide the full path in the "key" again - that path should be relative to the one you already "PUT" - so using / as "key" should work in your example
11 replies
Alexander Wellbrock
@lionax_gitlab
@thjaeckle Oh, I see. But why didn't it work when sending a PUT to https://twin.othermo.de/api/2/things/cool:my-fancy-device with the whole thing as payload and the same metadata. Shouldn't this work?
Thomas Jaeckle
@thjaeckle
yes, that's strange .. should work
Alexander Wellbrock
@lionax_gitlab
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Extended `AuthorizationContext` by method for chec…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
b3d588a
…king authorization based on granted on revoked AuthorizationSubjects.
Added further tests to `ImmutableAuthorizationContextTest`.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Changed unit tests to use `DittoHeaders.readGrante…
…
Unverified
This user has not uploaded their public key yet.
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
@thjaeckle
So please go ahead and create an issue. Maybe someone also requiring it picks it up, you are of course also very welcome to contribute ;)
Sign in to start talking
" \"accelerometer\": {\n" +
" \"properties\": {\n" +
" \"x\": 3.141,\n" +
" \"y\": 2.718,\n" +
" \"z\": 1,\n" +
" \"unit\": \"g\"\n" +
" }\n" +
" }\n" +
" }\n" +
" }\n" +
"}").asObject());
client.sendDittoProtocol(jsonifiableAdaptable).whenComplete((a, t) -> {
if (a != null) {
LOGGER.info("sendDittoProtocol: Received adaptable as response: {}", a);
}
if (t != null) {
LOGGER.warn("sendDittoProtocol: Received throwable as response", t);
}
});
client.twin().startConsumption().get();
client2.twin().startConsumption().get();
LOGGER.info("Subscribed for Twin events");
client.live().startConsumption().get();
client2.live().startConsumption().get();
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
Ok, I'll open an issue
Thomas Jaeckle
@thjaeckle
seems to be a problem only for "create thing" ..
Alexander Wellbrock
@lionax_gitlab
@thjaeckle I'm not creating a thing here, I'm basically doing a GET, parse the thing throw in some model data and do a put on the thing updating it
@thjaeckle am I supposed to be able to create metadata leafs for properties that do not exist on the thing?
Thomas Jaeckle
@thjaeckle
no
Alexander Wellbrock
@lionax_gitlab
yikes :D
I'm good at breaking stuff I suppose :'D
Thomas Jaeckle
@thjaeckle
what would be the point of "meta" data not referencing "real" data? :D
Alexander Wellbrock
@lionax_gitlab
maybe only to hint that there's more out there than the sole feature can comprehend? :D
Alexander Wellbrock
@lionax_gitlab
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
then again, Ditto would need to implement all of those bindings … implementing the HTTP binding, and using knative give you access to all of them at once
Sign in to start talking
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Jens Reimann
@ctron
well HTTP is one way to transport cloud events … you could transport cloud events also via Kafka, MQTT or AMQP 1.0
Sign in to start talking
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Jens Reimann
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Thomas Jaeckle
@thjaeckle
@ctron however supporting "cloud events" would not help you if Ditto would consume them via Kafka or AMQP 1.0 or MQTT, correct? ;)
Sign in to start talking
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
6797bbe
…dSubjects` instead of deprecated `readSubjects`.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Add revoked read subjects to headers of events and…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
0643e59
… messages at the outbound service boundaries. Deprecated `EffectedSubjectIds` in favour of `EffectedSubjects`.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
Sign in to start talking
@ctron
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Thomas Jaeckle
@thjaeckle
@lionax_gitlab the Ditto Java client has a quite extensive API for handling "live commands" (builder based so that a correct live command response and optionally a live event is returned as a response to a received live command) - for examples please take a look at:https://github.com/eclipse/ditto-clients/blob/master/java/src/test/java/org/eclipse/ditto/client/DittoClientUsageExamples.java#L342
Sign in to start talking
So while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
It gives you a common way to process those messages pre-Ditto … so e.g. you get those events from an HTTP/MQTT/ABC-endpoint and convert them to a cloud-event. Then store them in Kafka, process them through vorto, and finally sending them to ditto … all events are cloud events, and in the last step, the payload of that cloud event is a ditto protocol JSON
Sign in to start talking
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Alexander Wellbrock
@lionax_gitlab
Sign in to start talking
LOGGER.info("Subscribed for Live events/commands/messages");
System.out.println("\n\nContinuing with TWIN commands/events demo:");
useTwinCommandsAndEvents(client, client2);
System.out.println("\n\nFinished with TWIN commands/events demo");
}
if (shouldNotSkip("live.examples")) {
client.live().startConsumption().get();
client2.live().startConsumption().get();
System.out.println("\n\nAbout to continue with LIVE commands/events demo:");
promptEnterKey();
useLiveCommands(client, client2);
System.out.println("\n\nFinished with LIVE commands/events demo");
System.out.println("\n\nAbout to continue with LIVE messages demo:");
promptEnterKey();
useLiveMessages(client, client2);
System.out.println("\n\nFinished with LIVE messages demo");
Thread.sleep(500);
}
if (shouldNotSkip("search.examples")) {
System.out.println("\n\nAbout to continue with search commands:");
promptEnterKey();
useSearchCommands(client);
System.out.println("\n\nFinished with SEARCH commands demo");
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
So apparently what I was able to do just now is to push metadata which has no corresponding "real" counterpart. I'm now doing PUT https://twin.othermo.de/api/2/things/cool:my-fancy-device/features/MBUS/properties with updated metadata "keys" to /status/primaryAddress. Since out of laziness I'm sending all metadata along each request all features are now polluted with all the metadata I sent. Interestingly enough with empty objects for everything that SHOULD exist and expected-objects for everything which does not exist in that particular feature. I'll play around with it some more and so a decent write-up in an issue. I suppose I should just clean up my requests though... :/
Thomas Jaeckle
@thjaeckle
well in that case this would create a nested metadata /status/primaryAddress on the "real" data /features/MBUS/properties .. FMPOV that is how it is supposed to work
Alexander Wellbrock
@lionax_gitlab
Yeah, ok. I see why that could make sense
Alexander Wellbrock
@lionax_gitlab
Is it possible to send a live command via the HTTP REST API? I expect this API is only for the twin-channel and if I were to sent a live command I'd have to use on of the connectivity tools that support full ditto protocol?Initially I wanted to use modify commands over the live channel opposed to the twin channel to let the device validate the modify command before applying it and updating it's digital twin. The live commands should be sent via a HTTP REST client which I suppose doesn't work, so would you model this via messages instead or use the newly introduced desired state API?
Thomas Jaeckle
@thjaeckle
@lionax_gitlab that is "half supported" currently - #106 is still open to track thatit however is currently possible to just add a query parameter?live to HTTP requests which results in a live command being created instead of a twin commandwe however did not test or ensure that this already works everywhere as expected
2 replies
my gut says that it could already work - feedback is welcome here ^^
Alexander Wellbrock
@lionax_gitlab
Ok, then I'll probably gonna find out soon :D crossing fingers
Jens Reimann
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Sign in to start talking
Jens Reimann
@ctron
well this would be "yet another endpoint" for ditto … cloud events are not knative, and thus you could still use cloud events in a plain docker, or bare metal deployment
because it is easier to close the connection, than to manually re-implement connection pooling … anyways, in "serverless", the pod would get shut down after a few seconds anyway
Thomas Jaeckle
@thjaeckle
so for consuming "cloud events" Ditto would have to provide a new HTTP endpoint accepting Ditto Protocol JSON?I'm not sure if this fits the cloud events idea .. as those Ditto Protocol JSON messages are mainly commands to exec (e.g. create or modify a thing) or messages to pass through"Events" in the Ditto sense are e.g. a "ThingMofidied" event (emitted once a thing was modified in Ditto's persistence) - that event as Ditto Protocol JSON would from my understanding be an event to publish to another "cloud event" endpointSo while an HTTP endpoint accepting Ditto Protocol JSON is a valid requirement, I would not see what benefit the "cloud events" spec gives
Sign in to start talking
this issue
Mar 14, 2020
Issue eclipse#561: Fixed compilation errors.
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
1dd5404
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Fixed unit test errors regarding item orders in JS…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
376ce4d
Thread.sleep(500);
}
if (shouldNotSkip("load.test")) {
System.out.println("\n\nAbout to continue with small load test:");
promptEnterKey();
final int loadTestThings = 100;
final int loadTestCount = 10;
subscribeForLoadTestUpdateChanges(client2, loadTestCount * loadTestThings, false);
performLoadTestUpdate(client, loadTestCount, loadTestThings, false);
performLoadTestRead(client, loadTestCount, true);
Thread.sleep(1000);
}
if (shouldNotSkip("policies.examples")) {
System.out.println("\n\nAbout to continue with policy example:");
promptEnterKey();
addNewSubjectToExistingPolicy(client);
System.out.println("\n\nFinished with policy example");
}
client.destroy();
client2.destroy();
System.out.println("\n\nDittoClientUsageExamples successfully completed!");
System.exit(0);
}
@ctron
@thjaeckle did you read a bit about cloud events? have my PoC ready, pushing data to ditto via the websocket protocol … however that is rather ugly, as I need an additional process and use web sockets like HTTP requests … closing the socket after every request
Thomas Jaeckle
@thjaeckle
@ctron I read a little but I don't find the time to do anything in this direction - also the "knative" events stuff would only work in k8s and Ditto does support other deployment modes (e.g. docker compose is most widely used to simply getting started) as wellfor what are you building a PoC? why do you e.g. need to close the WS after each "request"?
Sign in to start talking
…ON arrays.
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Fixed further unit test errors.
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
458c7d9
Signed-off-by: Juergen Fickel <juergen.fickel@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: Fix a sonar issue. For real this time.
…
private static void addNewSubjectToExistingPolicy(final DittoClient client)
throws ExecutionException, InterruptedException {
client.twin().create()
.thenApply(thing -> thing.getPolicyEntityId()
.orElseThrow(() -> new IllegalStateException(("Could not get PolicyId from created Thing."))))
.thenCompose(policyId -> client.policies().retrieve(policyId))
.thenApply(policy -> {
LOGGER.info("Going to update the Policy {} with a new subject.", policy.getEntityId().orElse(null));
return policy;
})
.thenApply(policy ->
policy.toBuilder()
.forLabel("DEFAULT")
.setSubject(Subject.newInstance(SubjectId.newInstance("New:Subject")))
.build())
.thenCompose(updatedPolicy -> client.policies().update(updatedPolicy))
.thenAccept(v -> LOGGER.info("Policy was updated with new subject."))
.get();
}
private static void useTwinCommandsAndEvents(final DittoClient client, final DittoClient client2)
throws InterruptedException, ExecutionException {
final ThingId thingId = ThingId.of(NAMESPACE + ":dummy-" + UUID.randomUUID());
client2.twin().registerForThingChanges("globalThingChangeHandler", change ->
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
9c5fcfe
Signed-off-by: Yufei Cai <yufei.cai@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: don't make logger in AbstractGraphActor protected,…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
cb8d348
… this causes javadoc errors
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
LOGGER.info("Received Change on Client 2: {}", change.toString()));
client.twin().registerForThingChanges("globalThingHandler", change -> {
if (change.isFull()) {
LOGGER.warn("Received full Thing change: {}", change);
} else {
LOGGER.info("Received Thing change: {}", change);
}
});
client.twin().registerForFeaturesChanges("globalFeaturesHandler", change -> {
if (change.isFull()) {
LOGGER.warn("Received full Features change: {}", change);
} else {
LOGGER.info("Received Features change: {}", change);
}
});
client.twin().registerForFeatureChanges("globalFeatureHandler", change -> {
if (change.isFull()) {
LOGGER.warn("Received full Feature change: {}", change);
} else {
LOGGER.info("Received Feature change: {}", change);
}
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: disable "doclint" for javadocs in ditto-services-*…
…
Unverified
This user has not uploaded their public key yet.
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
8bb2f5d
… modules
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
w4tsn
pushed a commit
to w4tsn/ditto
that referenced
this issue
Mar 14, 2020
Issue eclipse#561: reverted non-working changes to fix javadoc errors…
…
Unverified
This user has not uploaded their public key yet.
});
client.twin().registerForFeaturePropertyChanges("globalFeaturePropertyHandler", "foo", change -> {
if (change.isFull()) {
LOGGER.warn("Received full Feature property change on feature 'foo': {}", change);
} else {
LOGGER.info("Received Feature property change on feature 'foo': {}", change);
}
});
client.twin()
.registerForFeaturePropertyChanges("globalFeaturePropertyHandlerZzz", "foo", "zzz", change -> {
if (change.isFull()) {
LOGGER.warn("Received full Feature property change on feature 'foo' for property 'zzz': {}",
change);
} else {
LOGGER.info("Received Feature property change on feature 'foo' for for property 'zzz': {}",
change);
}
});
client.twin().registerForAttributesChanges("globalAttributeHandler", change -> {
if (change.isFull()) {
LOGGER.warn("Received full Attribute change: {}", change);
} else {
LOGGER.info("Received Attribute change: {}", change);
GPG key ID: 39CF2E662793ABCD
Learn about signing commits
debe220
…; excluded "controlflow" package from javadoc being generated for
Signed-off-by: Thomas Jaeckle <thomas.jaeckle@bosch-si.com>
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Assignees
thjaeckle
Labels
enhancement
Projects
None yet
Milestone
1.1.0
Linked pull requests
Successfully merging a pull request may close this issue.
Signal enrichment when publishing events/messages
4 participants
© 2020 GitHub, Inc.
Terms
}
});
client.twin().registerForAttributeChanges("globalAttributeHandlerFoo", "foo", change -> {
if (change.isFull()) {
LOGGER.warn("Received full Attribute change for 'foo': {}", change);
} else {
LOGGER.info("Received Attribute change for 'foo': {}", change);
}
});
client.twin().create(thingId).handle((createdThing, throwable) -> {
if (createdThing != null) {
LOGGER.info("Created new thing: {}", createdThing);
} else {
LOGGER.error("Thing could not be created due to: {}", throwable.getMessage());
}
return client.twin().forId(thingId).putAttribute("new", OffsetDateTime.now().toString());
}).get();
final ThingId newId = ThingId.of(NAMESPACE + ":dummy-" + UUID.randomUUID());
final ThingBuilder.FromScratch newThingBuilder = Thing.newBuilder().setId(newId);
final Thing newThing = newThingBuilder.build();
client.twin().create(newThing).get();
client.twin().retrieve(JsonFieldSelector.newInstance("thingId"), thingId, newId).thenAccept(things ->
LOGGER.info("Retrieved Things: {}", things));
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
client.twin().delete(thingId).get();
client.twin().forId(thingId).retrieve().whenComplete((thingAsPersisted, ex) -> {
LOGGER.info("Thing that should be deleted: {}", thingAsPersisted);
LOGGER.info("Expected Exception: {}", ex.getMessage());
});
final ThingId evenNewerId = ThingId.of(NAMESPACE + ":dummy-" + UUID.randomUUID());
final Thing thing = ThingsModelFactory.newThingBuilder().setId(evenNewerId).build();
try {
client.twin().create(thing).handle((createdThing, throwable) -> {
if (createdThing != null) {
LOGGER.info("Created new thing: {}", createdThing);
} else {
LOGGER.error("Thing could not be created due to: {}", throwable.getMessage());
}
return client.twin().forId(evenNewerId).putAttribute("new", OffsetDateTime.now().toString());
}).get(10, SECONDS);
} catch (final TimeoutException e) {
e.printStackTrace();
}
try {
final ThingBuilder.FromScratch dummyThingBuilder =
Thing.newBuilder().setId(ThingId.of(NAMESPACE + ":dummy-" + UUID.randomUUID()));
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
final Thing dummyThing = dummyThingBuilder.build();
client.twin().create(dummyThing).get(10, SECONDS);
} catch (final TimeoutException e) {
e.printStackTrace();
}
// cleanup registrations:
client2.twin().deregister("globalThingChangeHandler");
client.twin().deregister("globalThingHandler");
client.twin().deregister("globalFeaturesHandler");
client.twin().deregister("globalFeatureHandler");
client.twin().deregister("globalFeaturePropertyHandler");
client.twin().deregister("globalFeaturePropertyHandlerZzz");
client.twin().deregister("globalAttributeHandler");
client.twin().deregister("globalAttributeHandlerFoo");
}
private static void useLiveCommands(final DittoClient backendClient, final DittoClient clientAtDevice)
throws ExecutionException, InterruptedException {
final ThingId thingId = ThingId.of(NAMESPACE + ":live-" + UUID.randomUUID().toString());
backendClient.twin().create(thingId).get();
// ###
// ###
// register for live commands at device and emit live commands in backend
LOGGER.info("[AT DEVICE] register handler for 'CreateThing' LIVE commands..");
promptEnterKey();
clientAtDevice.live()
.handleCreateThingCommands(command -> {
LOGGER.info("[AT DEVICE] Received live command: {}", command.getType());
LOGGER.info("[AT DEVICE] Thing to create: {}", command.getThing());
LOGGER.info("[AT DEVICE] Answering ...");
return command.answer()
.withResponse(CreateThingLiveCommandAnswerBuilder.ResponseFactory::created)
.withEvent(CreateThingLiveCommandAnswerBuilder.EventFactory::created);
});
LOGGER.info("[AT DEVICE] register handler for 'ModifyFeatureProperty' LIVE commands..");
clientAtDevice.live()
.forId(thingId)
.forFeature("temp-sensor")
.handleModifyFeaturePropertyCommands(command -> {
LOGGER.info("[AT DEVICE] Received live command: {}", command.getType());
command.getPropertyValue());
LOGGER.info("[AT DEVICE] Answering ...");
return command.answer()
.withResponse(ModifyFeaturePropertyLiveCommandAnswerBuilder.ResponseFactory::modified)
.withEvent(ModifyFeaturePropertyLiveCommandAnswerBuilder.EventFactory::modified);
});
LOGGER.info("[AT BACKEND] create a new LIVE Thing..");
promptEnterKey();
backendClient.live()
.create(thingId)
.whenComplete((thing, throwable) -> {
if (throwable != null) {
LOGGER.error("[AT BACKEND] Received error when creating the thing.", throwable);
} else if (thing.getEntityId().filter(thingId::equals).isPresent()) {
LOGGER.info("[AT BACKEND] Successfully created live Thing and got response: {}", thing);
} else {
LOGGER.warn("[AT BACKEND] Received unexpected thing {}.", thing);
}
});
LOGGER.info("[AT BACKEND] put 'temperature' property of 'temp-sensor' LIVE Feature..");
promptEnterKey();
backendClient.live()
.forFeature(thingId, "temp-sensor")
.putProperty("temperature", 23.21)
.whenComplete((_void, throwable) -> {
if (throwable != null) {
LOGGER.error("[AT BACKEND] Received error when putting the property: {}",
throwable.getMessage(), throwable);
} else {
LOGGER.info("[AT BACKEND] Putting the property succeeded");
}
});
// ##
// ##
// register for live events in backend and emit live events at device
LOGGER.info("[AT BACKEND] register for LIVE attribute changes of attribute 'location'..");
promptEnterKey();
backendClient.live()
.registerForAttributeChanges("locationHandler", "location", change -> {
change.getEntityId();
LOGGER.info("[AT BACKEND] Received change of attribute 'location': {}",
change.getValue().orElse(null));
});
LOGGER.info("[AT BACKEND] register for LIVE feature property changes of feature 'lamp'..");
backendClient.live()
.forFeature(thingId, "lamp")
.registerForPropertyChanges("lampPropertiesHandler",
change.getPath(),
change.getValue().orElse(null)));
LOGGER.info("[AT DEVICE] Emitting LIVE event AttributeModified for attribute 'location'..");
promptEnterKey();
clientAtDevice.live()
.forId(thingId)
.emitEvent(thingEventFactory ->
thingEventFactory.attributeModified("location",
JsonObject.newBuilder()
.set("longitude", 42.123)
.set("latitude", 8.123)
.build()
)
);
LOGGER.info("[AT DEVICE] Emitting LIVE event 'FeaturePropertyModified' for feature 'lamp', property 'on'..");
promptEnterKey();
clientAtDevice.live()
.forId(thingId)
.forFeature("lamp")
.emitEvent(featureEventFactory ->
featureEventFactory.featurePropertyModified("on",
JsonValue.of(true)
)
);
}
private static void useLiveMessages(final DittoClient backendClient, final DittoClient clientAtDevice)
throws InterruptedException, ExecutionException {
final ThingId thingId = ThingId.of(NAMESPACE + ":messages-" + UUID.randomUUID());
// first create Thing:
backendClient.twin().create(thingId).get();
LOGGER.info("[AT DEVICE] Registering for messages..");
promptEnterKey();
clientAtDevice.live().registerForMessage("globalMessageHandler", "hello.world", message -> {
message.toString());
message.reply().statusCode(HttpStatusCode.IM_A_TEAPOT).payload("Hello Teapot!").send();
});
clientAtDevice.live().registerForClaimMessage("globalClaimMessageHandler", String.class, claimMessage -> {
LOGGER.info("[AT DEVICE] Received Claim Message on Client 2: '{}'", claimMessage.getPayload().orElse(null));
claimMessage.reply().statusCode(HttpStatusCode.OK).payload("claim-acked").send();
});
LOGGER.info("[AT BACKEND] sending '{}' message..", KnownMessageSubjects.CLAIM_SUBJECT);
promptEnterKey();
backendClient.live().message().to(thingId).subject(KnownMessageSubjects.CLAIM_SUBJECT).payload("please-claim")
.send(String.class, (response, throwable) -> {
if (response != null) {
KnownMessageSubjects.CLAIM_SUBJECT,
response.getPayload().orElse(null), response.getHeaders());
} else {
LOGGER.error("[AT BACKEND] Got error when expecting a claim response: {}",
throwable.getMessage(),
throwable);
}
});
LOGGER.info("[AT BACKEND] sending message with subject 'hello.world' ..");
promptEnterKey();
backendClient.live().forId(thingId).message().from().subject("hello.world").payload("I am a Teapot")
.send(String.class, (response, throwable) ->
response.getPayload().orElse(null)));
}
private static void performLoadTestUpdate(final DittoClient client, final int updateCount,
final int thingCount, final boolean log) {
final JsonObject attributesExample = JsonFactory.newObjectBuilder()
.set("maker", "ACME Inc.")
.set("VIN", UUID.randomUUID().toString())
.set("rev", Math.random() * 1000.0)
.build();
final FeatureProperties featurePropertiesExample = FeatureProperties.newBuilder()
.set("aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", 32489324)
.set("bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb", false)
.set("ccccccccccccccccccccccccccccccccc",
UUID.randomUUID().toString() + ":" + UUID.randomUUID().toString())
.build();
final ExecutorService executorService = Executors.newFixedThreadPool(16);
for (int k = 1; k <= thingCount; k++) {
final int thingIdx = k;
executorService.execute(() ->
{
final ThingId thingId = ThingId.of(NAMESPACE + ":load-" + thingIdx + "-" + UUID.randomUUID());
final Thing thing = Thing.newBuilder().setId(thingId)
.setAttributes(attributesExample)
.setFeature("the-feature", featurePropertiesExample)
.build();
try {
client.twin().create(thing).get(10, TimeUnit.SECONDS);
} catch (final InterruptedException | ExecutionException | TimeoutException e) {
throw new IllegalStateException(e);
}
if (log) {
LOGGER.info("performLoadTestUpdate: Created new thing: {}", thing);
}
final long startTs = System.nanoTime();
final AtomicInteger integer = new AtomicInteger(updateCount);
for (int i = updateCount; i >= 0; i--) {
final int counter = i;
final long startTs2 = System.nanoTime();
client.twin().forId(thingId).putAttribute("counter", counter,
Options.Modify.responseRequired(false)).whenComplete((_void, throwable) ->
{
if (throwable != null) {
LOGGER.warn("performLoadTestUpdate: Updating attribute failed: {}", throwable.getMessage());
} else {
final double duration = getDuration(startTs2);
if (log) {
counter, duration);
}
integer.decrementAndGet();
}
});
}
while (integer.get() > 0) {
try {
Thread.sleep(10);
} catch (final InterruptedException e) {
Thread.currentThread().interrupt();
throw new IllegalStateException(e);
}
}
final double duration = getDuration(startTs);
"that are ~{}req/s", updateCount, duration, (int) (updateCount / duration * 1000));
});
}
}
private static void subscribeForLoadTestUpdateChanges(final DittoClient client, final int count,
final boolean log) {
final long startTs = System.nanoTime();
final AtomicInteger integer = new AtomicInteger(count);
client.twin().registerForThingChanges("loadTestChanges", change -> {
if (change.getAction() == ChangeAction.UPDATED) {
if (log) {
integer.get(), getDuration(startTs));
}
if (integer.getAndDecrement() == 1) {
final double duration2 = getDuration(startTs);
" that are ~{}changes/s", count, duration2, (int) (count / duration2 * 1000));
}
}
});
}
private static void useSearchCommands(final DittoClient client) {
final String namespace =
CONFIG.getProperty("ditto.search.namespace", CONFIG.getProperty("ditto.namespace"));
final String rql1 = "like(thingId,\"" + namespace + ":*0\")";
final String options1 = "sort(-thingId),size(1)";
client.twin()
.search()
.stream(searchQueryBuilder -> searchQueryBuilder.namespace(namespace)
.filter(rql1)
.options(builder -> builder.sort(s -> s.desc("thingId")).size(1))
.initialDemand(1)
.demand(1)
.fields("thingId")
)
.forEach(thing -> {
// run in main thread
LOGGER.info("Received: <{}>", thing.getEntityId().orElse(null));
});
LOGGER.info("Done.\n");
final String rql2 = "not(exists(thingId))";
LOGGER.info("Expecting empty search results for <{}>...", rql2);
client.twin()
.search()
.stream(searchQueryBuilder -> searchQueryBuilder.namespace(namespace)
.filter(rql2)
.fields("thingId")
)
.forEach(thing -> {
// run in main thread
LOGGER.info("Received: <{}>", thing.getEntityId().orElse(null));
});
LOGGER.info("Done.\n");
final String rql3 = "not(exist(thingId";
LOGGER.info("Expecting error for <{}>...", rql3);
try {
client.twin()
.search()
.stream(searchQueryBuilder -> searchQueryBuilder.filter(rql3))
.forEach(thing -> {
// run in main thread
LOGGER.error("Received unexpected: <{}>", thing);
});
LOGGER.error("Got no error! Something is wrong.");
} catch (final DittoRuntimeException e) {
if (e.getErrorCode().equals("rql.expression.invalid")) {
LOGGER.info("Got expected error: <{}>", e.toJson());
} else {
LOGGER.error("Got unexpected error! Something is wrong: <{}>", e.toJson());
}
}
LOGGER.info("Done.\n");
}
private static double getDuration(final long startTimeStamp) {
final int nanosecondsToMillisecondsFactor = 1_000_000;
return (double) (System.nanoTime() - startTimeStamp) / nanosecondsToMillisecondsFactor;
}
private static void performLoadTestRead(final DittoClient client, final int count, final boolean log)
throws InterruptedException, ExecutionException {
final ThingId thingId = ThingId.of(NAMESPACE + ":load-read-" + UUID.randomUUID());
client.twin().create(thingId).get();
if (log) {
LOGGER.info("performLoadTestRead: Created new thing: {}", thingId);
}
final long startTs = System.nanoTime();
final AtomicInteger integer = new AtomicInteger(count);
for (int i = count; i >= 0; i--) {
final int counter = i;
final long startTs2 = System.nanoTime();
client.twin()
.forId(thingId)
.retrieve(JsonFieldSelector.newInstance("thingId"))
.thenAccept(thing -> {
if (log) {
getDuration(startTs2));
}
integer.decrementAndGet();
});
}
client.twin().forId(thingId).putAttribute("finished", true);
while (integer.get() > 0) {
Thread.sleep(10);
}
final double duration = getDuration(startTs);
duration, (int) (count / duration * 1000));
}
private static void promptEnterKey() throws InterruptedException {
if (promptToContinue()) {
Thread.sleep(500);
System.out.println("Press \"ENTER\" to continue...");
final Scanner scanner = new Scanner(System.in);
scanner.nextLine();
}
}
/**
* Create a messaging provider according to the configuration.
*
* @return the messaging provider.
*/
public static MessagingProvider createMessagingProvider() {
final MessagingConfiguration.Builder builder = WebSocketMessagingConfiguration.newBuilder()
.endpoint(DITTO_ENDPOINT_URL)
.jsonSchemaVersion(JsonSchemaVersion.V_2)
.reconnectEnabled(false);
final ProxyConfiguration proxyConfiguration;
if (PROXY_HOST != null && !PROXY_HOST.isEmpty()) {
proxyConfiguration = ProxyConfiguration.newBuilder()
.proxyHost(PROXY_HOST)
.proxyPort(Integer.parseInt(PROXY_PORT))
.build();
builder.proxyConfiguration(proxyConfiguration);
} else {
proxyConfiguration = null;
}
if (DITTO_TRUSTSTORE_LOCATION != null) {
builder.trustStoreConfiguration(TrustStoreConfiguration.newBuilder()
.location(DITTO_TRUSTSTORE_LOCATION)
.password(DITTO_TRUSTSTORE_PASSWORD)
.build());
}
final AuthenticationProvider<WebSocket> authenticationProvider;
if (DITTO_DUMMY_AUTH_USER != null) {
authenticationProvider =
AuthenticationProviders.dummy(DummyAuthenticationConfiguration.newBuilder()
.dummyUsername(DITTO_DUMMY_AUTH_USER)
.build());
} else if (DITTO_OAUTH_CLIENT_ID != null) {
final ClientCredentialsAuthenticationConfiguration.ClientCredentialsAuthenticationConfigurationBuilder
authenticationConfigurationBuilder =
ClientCredentialsAuthenticationConfiguration.newBuilder()
.clientId(DITTO_OAUTH_CLIENT_ID)
.clientSecret(DITTO_OAUTH_CLIENT_SECRET)
.scopes(DITTO_OAUTH_SCOPES)
.tokenEndpoint(DITTO_OAUTH_TOKEN_ENDPOINT);
if (proxyConfiguration != null) {
authenticationConfigurationBuilder.proxyConfiguration(proxyConfiguration);
}
authenticationProvider =
AuthenticationProviders.clientCredentials(authenticationConfigurationBuilder.build());
} else {
authenticationProvider =
AuthenticationProviders.basic(BasicAuthenticationConfiguration.newBuilder()
.username(DITTO_USERNAME)
.password(DITTO_PASSWORD)
.build());
}
return MessagingProviders.webSocket(builder.build(), authenticationProvider);
}
private static boolean shouldNotSkip(final String propertyName) {
return !Boolean.parseBoolean(CONFIG.getProperty("skip." + propertyName, "false"));
}
private static boolean promptToContinue() {
return Boolean.parseBoolean(CONFIG.getProperty("prompt.to.continue", "true"));
}
static {
try {
final Properties config = new Properties();
if (new File(PROPERTIES_FILE).exists()) {
config.load(new FileReader(PROPERTIES_FILE));
} else {
final InputStream i =
Thread.currentThread().getContextClassLoader().getResourceAsStream(PROPERTIES_FILE);
config.load(i);
i.close();
}
PROXY_HOST = config.getProperty("proxy.host");
PROXY_PORT = config.getProperty("proxy.port");
DITTO_ENDPOINT_URL = config.getProperty("ditto.endpoint");
if (!config.getProperty("ditto.truststore.location").isEmpty()) {
DITTO_TRUSTSTORE_LOCATION =
DittoClientUsageExamples.class.getResource(config.getProperty("ditto.truststore.location"));
} else {
DITTO_TRUSTSTORE_LOCATION = null;
}
DITTO_TRUSTSTORE_PASSWORD = config.getProperty("ditto.truststore.password");
DITTO_DUMMY_AUTH_USER = config.getProperty("ditto.dummy-auth-user");
DITTO_USERNAME = config.getProperty("ditto.username");
DITTO_PASSWORD = config.getProperty("ditto.password");
DITTO_OAUTH_CLIENT_ID = config.getProperty("ditto.oauth.client-id");
DITTO_OAUTH_CLIENT_SECRET = config.getProperty("ditto.oauth.client-secret");
DITTO_OAUTH_SCOPES =
Arrays.stream(config.getProperty("ditto.oauth.scope").split(" ")).collect(Collectors.toSet());
DITTO_OAUTH_TOKEN_ENDPOINT = config.getProperty("ditto.oauth.token-endpoint");
NAMESPACE = config.getProperty("ditto.namespace");
CONFIG = config;
} catch (final IOException e) {
throw new IllegalStateException(e);
}
}
}
Copy lines
Copy permalink
View git blame
Reference in new issue
Go
© 2020 GitHub, Inc.
Terms
Privacy
Cookie Preferences
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
You can’t perform that action at this time.
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
Learn more.
Accept
Reject
We use optional third-party analytics cookies to understand how you use GitHub.com so we can build better products.
You can always update your selection by clicking Cookie Preferences at the bottom of the page.
For more information, see our Privacy Statement.
Essential cookies
Learn more
Always active
Analytics cookies
We use analytics cookies to understand how you use our websites so we can make them better, e.g. they're used to gather information about the pages you visit and how many clicks you need to accomplish a task.
Learn more
Accept
Reject
Save preferences
